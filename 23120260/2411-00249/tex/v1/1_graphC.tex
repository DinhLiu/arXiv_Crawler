\documentclass{article}
\usepackage{arxiv}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{balance}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{tabularx}

%\usepackage{multicolumn}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}


\newcommand\Tesic[1]{{\color{blue!40!black!30!red}\em Jelena: #1}}
\newcommand\Mo[1]{{\color{blue!40!black!30!red}\em Mo: #1 ?}}

\newtheorem{lemma}{Lemma}[section]
\newtheorem{Definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{fact}{Fact}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{axiom}{Axiom}[section]
\newtheorem{cond}{Condition}[section]
\newtheorem{property}{Property}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{proof}{Proof}[section]
\title{GraphC: Parameter-free Hierarchical Clustering of Signed Graph Networks}

\author{Muhieddine Shebaro, Lucas Rusnak, Martin Burtscher, and Jelena Te\v{s}i\'{c}}


\begin{document}

\maketitle
\begin{abstract} Spectral clustering methodologies, when extended to accommodate signed graphs, have encountered notable limitations in effectively encapsulating inherent grouping relationships. Recent findings underscore a substantial deterioration in the efficacy of spectral clustering methods when applied to expansive signed networks. We introduce a scalable hierarchical Graph Clustering algorithm denominated \emph{GraphC}. This algorithm excels at discerning optimal clusters within signed networks of varying magnitudes. \emph{GraphC} aims to preserve the positive edge fractions within communities during partitioning while concurrently maximizing the negative edge fractions between communities. Importantly, \emph{GraphC} does not require a predetermined cluster count (denoted as k). Empirical substantiation of \emph{GraphC} 's efficacy is provided through a comprehensive evaluation involving fourteen datasets juxtaposed against ten baseline signed graph clustering algorithms. The algorithm's scalability is demonstrated through its application to extensive signed graphs drawn from Amazon-sourced datasets, each comprising tens of millions of vertices and edges. A noteworthy accomplishment is evidenced, with an average cumulative enhancement of 18.64\% (consisting of the summation of positive edge fractions within communities and negative edge fractions between communities) over the second-best baseline for each respective signed graph. It is imperative to note that this evaluation excludes instances wherein all baseline algorithms failed to execute comprehensively.
\end{abstract}
clustering, signed network, community detection, and structural balance.

%Motivation and Problem definition 
\section{Introduction}
\label{sec-problem}

Communities within a network are sets of vertices characterized by denser interconnections among them than with the broader network. These communities may exhibit either distinct vertex sets or overlap, where vertices partake in multiple communities. The detection of community structure holds great importance, unveiling latent insights into relationships and dynamic mechanisms within complex networks spanning various domains, ranging from biological to social networks. The inherent complexity of these network systems frequently causes the substantial datasets to surpass individual systems' computational capacities, necessitating data partitioning for distributed processing. The efficiency of such partitioning schemes in community detection algorithms is contingent upon various factors. Numerous methodologies, encompassing local optima pursuit, statistical inference, and machine learning, have been posited to unveil community structure. While state-of-the-art community discovery algorithms in unsigned graphs adeptly handle vast networks comprising millions of vertices and edges \cite{edssjsED801E9B20231201}, the modeling of unsigned graphs falls short in capturing the complex relationships within networks. The ascendancy of signed graph modeling as a more fruitful and meaningful data representation is evident. Recent investigations demonstrate the struggles of contemporary signed graph methods in recovering communities within graphs featuring mere thousands of vertices and hundreds of thousands of edges \cite{2022Cluster}. The latest research underscores the challenges posed by spectral methods in recovering community structure within sparse networks, even with the incorporation of normalization techniques \cite{2021cucuringu}. This finding aligns with our conclusions: there is a significant degradation in the performance of spectral methods for clustering large, sparse signed networks derived from authentic data sources \cite{2022Survey}. In the realm of signed networks, balance theory stands as a pivotal concept, explaining the evolution of attitudes within networks. Established by Heider \cite{1958Abelson} and subsequently formalized mathematically by Harary, who introduced k-way balance \cite{Har2,Harary1968}, balance theory has found applications in predicting edge sentiment, content and product recommendations, and anomaly detection in various domains \cite{derr2020link,garimella2021political,interian2022network,amelkin2019fighting}.

\subsection{Spectral Clustering of Real Signed Graphs} 

Spectral clustering was proposed in 1973 by Donath and Hoffman \cite{donath}, and the proposition is that the graph can be partitioned using the eigenvectors of the adjacency matrix. We outline the generic spectral clustering process in four steps: (1) computation of the Laplacian variant and identification of clusters ($k$); (2) derivation of $k$ eigenvectors corresponding to the $k$ smallest eigenvalues; (3) formation of the eigenvector matrix U to reduce dimensionality; and (4) application of k-means++ to cluster features. The SigNeT package, employed for spectral methods in signed networks, encompasses multiple Laplacian variants, all presumed to be positive semi-definite \cite{aldogl2018}. The scalability of spectral clustering algorithms is limited in the context of real signed networks: (i) the substantial time required for the solver to formulate eigenvectors with their associated eigenvalues, and (ii) the susceptibility to spectral pollution or eigenvalue pollution, manifesting as instability in the approximation implementations for large matrices and consequential error fluctuations \cite{BOULTON20161}. A recent survey has provided a proof-of-concept and practical evaluation of these limitations in actual signed graphs \cite{2022Survey}. The survey falls short of delineating the breaking points of signed Laplacians concerning algorithmic assumptions (e.g., small world, diameter) and characteristics specific to signed networks (e.g., density, sparsity) \cite{2022Survey}.

Another significant drawback in contemporary signed graph clustering algorithms pertains to the challenging task of determining the suitable number of communities ($k$) before algorithmic execution. A common approach for dealing with this is to utilize the elbow method. However, this method is subjective in nature because it introduces variability, rendering it dependent on individual perspectives. Furthermore, the decision-making process is derailed by various factors and network characteristics, including sparsity, average degree, and overall network structure, which collectively influence the selection of the optimal number of communities. The evaluation of why one community partitioning surpasses another is not clear in the absence of meaningful ground truth, as in \cite{2022Survey}.

\subsection{Research Contributions}
\label{sec-obj}
\emph{GraphC} is a term contraction of a \emph{graph clustering} phrase. \emph{GraphC} is a parameter-free clustering algorithm for signed graphs. $G_i$ notes the signed graph with an unsigned topology $G$ (depicted in Figure~\ref{fig-SpecClustGraphs}), and $G_{ij}$ symbolize a collection of vertex sets discovered by clustering algorithm $j$. \emph{GraphC} reformulates the clustering problem by shifting the emphasis from minimizing the combined count of positive edges between communities and negative edges within communities. The loss minimizes the fraction of positive edges \emph{between} communities and the fraction of negative edges \emph{within} communities for algorithm $j$ applied to the signed graph $G_i$. We quantify the positive edges outside communities as $pos_{out}(G_{ij})$ (Eq.~\ref{eq-PosOut}), and the negative edges within communities as $neg_{in}(G_{ij})$ (Eq.~\ref{eq-NegIn}) for algorithm $j$ operating on the signed graph $G_i$. \emph{GraphC} identifies optimal clusters without the need for a predefined $k$ and a spectral decomposition solver. \textbf{Paper Contributions:} 
\begin{enumerate}
\item \emph{Spectral-Balance duality:} we prove that Harary cuts from a \emph{balanced} signed network are equivalent to an eigenvector with a 0 eigenvalue for that balanced network. 
 \item \emph{GraphC} implements this theoretical novelty and directly performs Harary cuts on the balanced signed graph by purging the negative edges than it is using Laplacian. 
  \item \emph{GraphC} algorithm can process signed graphs with tens of millions of vertices and edges. Parameterized trade-off between speed and the overall quality of the clustering that allows the algorithm to scale on a single workstation. 
   \item \emph{GraphC} is $k$-independent: it does not require a predefined number of clusters to produce a high-quality clustering. The parameters used in the algorithm are dependent on computing resources.
\item \emph{GraphC} addresses the positive-negative edge imbalance that naturally occurs in most signed networks as it takes equally into account the contribution of positive edges and the negative edges in the graph for clustering optimization.
\end{enumerate}

\section{Related Work}
\label{sec-related}

%In signed networks, negative weights denote antagonistic relationships or conflicting opinions \cite{2022Survey}. Signed networks play a pivotal role in various domains, including medicine, criminology, and business, where community identification is a prevalent task.

The diapason of existing approaches for community detection in signed networks forms a diverse landscape. Xhiang et al. propose an algorithm for clustering signed graphs utilizing the balanced normalized cut, demonstrating commendable clustering results and recognized as an efficient approach  \cite{2012chiang}. The \emph{Signed Positive over Negative Generalized Eigenproblem} spectral-based approach necessitates the specification of $k$ as it formulates clustering as a generalized eigenvalue problem, enhancing a well-defined objective function \cite{pmlr-v89-cucuringu19a}. The approach relying on the signed Hessian for clustering also requires a predefined $k$. It emphasizes the advantages of non-backtracking operators with the computational and memory efficiencies inherent in real symmetric matrices \cite{Saade2014SpectralCO}.

He et al. \cite{he2022sssnetsemisupervisedsignednetwork} use modified social network analysis and triangle balancing heuristics ("friend of my friend is my friend") to address the issue for cluster discovery based on a modified version of Heider balance theory. First, the authors employ a signed mixed-path aggregation (SIMPA) method to construct the vertex embedding. Consequently, this vertex embedding produces probabilities for cluster assignments. The clustering process involves training with a weighted combination of supervised and unsupervised loss functions, with the unsupervised component being a probabilistic balanced normalized cut. The algorithm uses labels from SPONGE (SPO) for some signed graphs to execute the clustering, building a dependency on other signed graph clustering algorithms. Combining positive and negative Laplacians using matrix power means is also proposed as a modification of the Laplacian \cite{means}. Note that the authors do not provide an implementation for the baseline comparison in \cite{means}. Graph neural networks (GNN) that rely on the social balance theory have been used for signed network clustering for the data with a significant positive class imbalance in \cite{gnnasine} and \cite{bridge}. The primary obstacle in employing graph neural networks for categorizing signed networks lies in the accurate management of negative connections and the integration of both positive and negative connections into a unified model that can effectively deduce node representations \cite{convsigned}. On the other hand, some researchers \cite{siren} argue that using opposing edges in Graph Neural Networks (GNNs) when developing a recommendation system for signed networks can be problematic. They state that these opposing edges can disrupt the network's homophily, which is the tendency of nodes to connect with similar ones. This disruption can make the transmission of messages to dissimilar nodes ineffective, potentially compromising the performance of the recommendation system. Hence, careful consideration is needed when designing GNNs for such applications. 


Gholami et al. \cite{overlapping} propose a new approach for detecting overlapping communities based on  Neutrosophic theory, and it consists of two phases. In the initial stage, the Signed Graph Convolutional Network (SGCN) is used to position nodes within a space of reduced dimensions. This step effectively encapsulates the architecture of the signed network and portrays it in a more compact space. Following this, the neutrosophic c-means clustering method is employed in the subsequent stage to allocate nodes to various communities.

\begin{figure*}[!ht]
    \centering
    \includegraphics[scale=0.55]{transparent_updated.pdf}
    \caption{\textbf{Dotted} lines are negative edges whereas the \textbf{sold} lines are positive edges. Top: A graph $G$, a balanced graph $G_1$ obtained by switching (changing the sign of the edges originating in) $v_1$, a balanced graph $G_2$ obtained by switching $v_1$ and $v_2$, a balanced graph $G_3$ by switching $v_2$ and $v_3$, and a balanced graph $G_4$ by switching $v_4$. $G_5$, $G_6$, $G_7$ and $G_8$ are examples of unbalanced states. Bottom: Harary Cuts of nearest stable states introduced in \cite{2021Cloud} from $G_5$ graph.}
    \label{fig-SpecClustGraphs}
\end{figure*}
%Dr. Tesic, we have some unbalanced states here because we need a G5 illustration for Table 1. The other examples of unbalanced states are used merely as examples for the reader of what makes a state balanced or not. To fit the picture horizontally (top), make it the same size as the bottom one in the same Figure. 

\section{Balanced-Spectral Duality in Signed Networks}
\label{sec-Duality}

In this section, we lay the groundwork for the terminology and properties of baseline signed graphs and introduce the duality theory of near-balanced states of the signed graph and spectral analysis.

\subsection{Fundamental Cycle Basis}
\begin{Definition}
Graph $G_i$ is a \textbf{subgraph} of a Graph $G$ if \textbf{all} edges and vertices of $G_i$ are contained in $G$. \label{def:Subgraph}
\end{Definition}

\begin{Definition}
\textbf{Path} is a sequence of distinct edges $m$ that connect a sequence of distinct vertices $n$ in a graph. \textbf{Connected Graph} has a path that joins any two vertices  \textbf{Cycle} is a path that begins and ends at the same vertex  \textbf{Cycle Basis} is a set of simple cycles that forms a basis of the cycle space. \label{def:CycleBasis}
\end{Definition}
\begin{Definition}
For the underlying Graph $G$, let $T$ be the spanning tree of $G$, and let an edge $m$ be an edge in $G$ between vertices $x$ and $y$ that is \emph{NOT} in the spanning tree $T$  Since the spanning tree spans all vertices, a unique path in $T$ between vertices $x$ and $y$ does not include $m$. \textbf{The fundamental cycle} is any cycle that is built using path in $T$ plus edge $m$ in graph $G$. \label{def:FundamentalCycle}
\end{Definition}

\begin{corollary}

For a given graph $G$, when we select the cycles formed by combining a path in the tree and a single edge outside the tree, we are for the fundamental cycle basis. For the Graph $G$ with $N$ vertices and $M$ edges, there are precisely $M-N+1$ fundamental cycles.
\end{corollary}

\subsection{Balanced Signed Graphs}
\label{ssec-Balance}
\begin{Definition}
\textbf{Signed graph} $G=(G, G)$ consists of underlying unsigned graph $G$ and an edge signing function $G : m \rightarrow \{+1,-1\}$. The edge $m$ can be positive $m^+$ or negative $m^-$. \textbf{Sign} of a sub-graph is \emph{product} of the edges signs. \textbf{Balanced Signed graph} is a signed graph where every cycle is positive  \textbf{Frustration} of a signed graph is defined as the number of candidate edges whose sign needs to be switched for the graph to reach the balanced state  Figure~\ref{fig-SpecClustGraphs} (Top, balanced states) shows an example signed network and its balanced states.
\label{def:SignedGraph}
\end{Definition}

\begin{theorem}[\cite{Har2}] If a signed subgraph $G'$ is balanced, the following are equivalent:
\begin{enumerate}
 \setlength{\leftmargin}{0pt}
    \item $G'$ is balanced. (All circles are positive.)
    \item For every vertex pair $(v_i, v_j) in G'$, all $(v_i, v_j)$-paths have the same sign.
    \item $Fr(G') = 0$ (The frustration of $G'$ is zero).
    \item A vertex set can be divided into two groups, $U$ and $W$. This division of the vertex set into ($U$, $W$) is known as the Harary-bipartition.
\end{enumerate}
\label{t:HararyCut}
\end{theorem}

The formation of the Harary cut starts with the deletion of the opposing edges in each balanced state in the frustration cloud of the signed graph as illustrated in Figure~\ref{fig-SpecClustGraphs} (bottom). The trivial unbalanced signed Graph in this Figure consisting of 4 vertices and five edges yields eight total nearest balanced states. Note that a Harary cut can yield multiple connected components, and the input graph might contain many initially connected components where Harary cuts and balancing take place in every element. Prior, we have characterized signed graphs through the frustration cloud \cite{2021Cloud}, a collection of nearest balanced states, and then introduced an improved and parallelizable way to discover the nearest balanced states in extensive signed data efficiently \cite{2021Alabandi}.

\subsection{Spectral Clustering and Balanced States}

A signed graph is \emph{balanced} if the graph has no cycles with an odd number of negative edges. \emph{switch} operation involves changing the sign of all edges connected to a specific vertex as observed when switching $v_1$ in $G$ to obtain $G_1$ in Figure~\ref{fig-SpecClustGraphs}. Switching equivalence in this context means that two balanced signed graphs can be transformed into each other through a series of switch operations, as shown in the following example. The balanced signed graphs for the same underlying Graph $G$ in Figure~\ref{fig-SpecClustGraphs} (Top) are switching equivalents \cite{Marsden2013EIGENVALUESOT}. $G_2$ and $G_3$ in Figure~\ref{fig-SpecClustGraphs} (Top) are switching equivalent because we can obtain $G_3$ by switching $v_1$ and $v_3$ in $G_2$. The critical point is that switching operations preserve the balanced nature of the Graph as they do not alter the overall balance or imbalance of the Graph \cite{2021Cloud}. Not only do we get the same eigenvalues, but the eigenvectors only differ by a multiple of $-1$ for each vertex switched.

\begin{table}[!ht]
\caption{Balanced signed graphs $G$, $G_1$, and $G_2$ are isospectral: they have identical eigenvalues, and their eigenvectors differ. $G_5$ is an unbalanced graph, and its eigenvalues and eigenvectors differ.}
\label{tab-isospectral} %\footnotesize
\setlength\tabcolsep{1pt}
\centering
\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
& \multicolumn{12}{c|}{Balanced Graphs} & \multicolumn{4}{c}{Unbalanced Graph} \\ \hline
Graph & \multicolumn{4}{c|}{$G$} & \multicolumn{4}{c|}{$G_1$} &  \multicolumn{4}{c|}{$G_2$} & \multicolumn{4}{c}{$G_5$} \\ \hline
Eigen & $0$ & $2$ & $4$ & $4$ &  & &  &  & $0$ & $2$ & $4$ & $4$ &  &  &  & \\
values & &  & & & $0$ & $2$ & $4$ & $4$ &  & & & & $2-\sqrt{2}$ & $3-\sqrt{3}$ & $2+\sqrt{2}$ & $3+\sqrt{3}$ \\ \hline
& 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1& 1& -1 & 1\\ 
Eigen & 1 & 1 & 0 & 1 & -1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & $\sqrt{2}$ & 0&  $\sqrt{2}$& 0 \\ 
vectors& 1 & 0 & -1 & -2 & -1 & 0 & 1 & -2 & -1 & 0 & 1 & 2 & -1 & 1& 1 &1\\
 & 1 & -1 & 0 & 1 & -1 & -1 & 0 & 1 & -1 & 1 & 0 & -1  & 0 & $\frac{1+\sqrt{3}}{2}$ & 0 &  $\frac{1-\sqrt{3}}{2}$\\
\end{tabular}
\end{table} Note that the spectral clustering results in zero eigenvalues as many times as there are clusters in the data \cite{Marsden2013EIGENVALUESOT}. The zero eigenvalues have an eigenspace with a basis of vectors that only have zeros and ones, and these vectors indicate which vertices belong to each cluster \cite{Marsden2013EIGENVALUESOT}. In Table~\ref{tab-isospectral}, for a connected graph G of 4 vertices with all positive edges, the eigenvector with the 0 eigenvalue consists entirely of ones. 

All balanced signed graphs are switching equivalent to all positive signed graphs with the same topology. This implies that when performing spectral analysis on such graphs, the eigenvalues remain the same, as illustrated in Table~\ref{tab-isospectral}. The corresponding eigenvectors only differ by a multiple of -1 for each switched vertex, as illustrated with $G$, $G_1$, and $G_1$ eigenvalues and eigenvectors from Figure~\ref{fig-SpecClustGraphs} in Table~\ref{tab-isospectral}. This property makes the study of spectral characteristics more manageable, as it allows for a direct comparison between different balanced signed graphs while preserving their essential structural features. The multiplicity of the $0$ eigenvalue counts the number of connected components of the underlying graph when balanced. The Laplacian for a balanced signed graph $G_{ij}$ can be decomposed into
\begin{equation}
 \mathbf{L}_{G} = \mathbf{I}_{W}\mathbf{L}_{G}\mathbf{I}_{W}
\end{equation}
where $G$ is the Laplacian of the underlying Graph, and $\mathbf{I}_{W}$ is the identity matrix, except the diagonal entries corresponding to the vertices of $W \subseteq V$ are $-1$.
\begin{theorem}
    The Laplacian matrices of balanced signed graphs of the same underlying Graph are isospectral. Table~\ref{tab-isospectral} exemplifies this using the same Graph G in Figure~\ref{fig-SpecClustGraphs} (Top, balanced states) whereas $G_5$ column in Table~\ref{tab-isospectral} shows the spectral clustering approach with an unbalanced state.
\end{theorem}
\begin{proof}
    Switching does not change the cycle signs. The signs of its cycles determine the characteristic polynomial \cite{OHSachs}.
\end{proof}

\begin{theorem}
    For a connected balanced signed graph $G_{ij}$, the entries of the $0$-eigenvector are $+1$ or $-1$. Partitioning the vertices along the entry values of the $0$-eigenvector corresponds to the Harary cut of the balanced signed Graph.
\end{theorem}
\begin{proof}
    Since $G_{ij}$ is balanced, it is isospectral to the underlying Graph $G$. Since $G$ is connected, the dimension of the $0$-eigenspace is $1$, and the vector $\mathbf{1}$ consisting of all $ 1$'s is a basis for that eigenspace  Switching a vertex $v$ negates both row and column $v$ in  $\mathbf{L}_{G}$ to produce $\mathbf{L}_{G}$, thus negating the $v$-entry of the basis vector $\mathbf{1}$.  
\end{proof}

On the other hand, if a signed graph is not balanced, $0$ is not an eigenvalue, and the structural and sentiment framework of the signed graph \emph{dissolves into the geometry}, as illustrated in Table~\ref{tab-isospectral} for $G_5$. Spectral methods determine outcomes based on the geometry of the eigenvectors. 

Thus, we conclude that the Harary bisects form using a spectral approach and vice versa. After balancing a signed network, we can construct its balanced Laplacian matrix, and the spectral decomposition of the matrix yields the eigenvectors with their associated eigenvalues. f balanced d and connected, there is a $1$ dimensional kernel, and the associated $0$ eigenvector entries give us the Harary cut.

\section{Measuring Signed Graph Clustering Efficacy}
\label{sec-measure}
\begin{figure}[!ht]
    \centering
    \includegraphics[width=3.1in]{example_unhappy.pdf}
    \caption{An illustration emphasizing the advantage of measuring the quality of a clustering assignment in a signed graph using the summation of the fraction of positive edges within communities and the fraction of negative edges between communities. \textbf{Dotted} lines are negative edges whereas the \textbf{sold} lines are positive edges.}
    \label{fig-example_unhappy}
\end{figure}  Consider two clustering assignments for the network illustrated in Figure~\ref{fig-example_unhappy}. In the absence of ground truth and training data for the community assignment in signed networks, state-of-the-art research uses the \emph{unhappy ratio}. The \emph{unhappy ratio} $U_i$ is defined in Eq.~\ref{eq-un} for a set of communities produced by method $j$ in the signed graph $G_i$: \begin{equation} \label{eq-un}
U_{ij}=\frac{pos_{between}+neg_{within}}{pos_{between}+ pos_{within}+neg_{between}+neg_{within}}
\end{equation}
\noindent The $pos_{between}$, $pos_{within}$, $neg_{within}$, and $neg_{between}$ are the number of positive edges between communities, the number of positive edges within communities, the number of negative edges within communities, and negative edges between communities, respectively. Note that the \emph{unhappy} ratio measures the quality of the clustering assignment in SSSNet experiments in \cite{he2022sssnetsemisupervisedsignednetwork}. 

The \emph{unhappy} ratio for both clustering approaches in Figure~\ref{fig-example_unhappy} is $0.25$. The clustering assignment on the right seems more effective as it avoids disregarding \emph{all} negative edges, successfully segregates two communities (1,4,8 and 2,3,5), and accurately classifies \emph{most} positive edges. The \emph{unhappy} ratio does not capture that measure. The measure fails to capture the quality of clustering real signed networks, as the \emph{unhappy} ratio favors positive edges and trivial clustering cases in networks where the typical number of negative edges is 5-10 times smaller \cite{2022Survey}. 

\noindent For a signed graph with 1000 edges, where 900 edges are positive, and the remaining 100 are negative, let's assume the first clustering has 400 $pos_{between}$, 500 $pos_{within}$, 50 $neg_{within}$, and 50 $neg_{between}$, resulting in an unhappy score $U_1$ of 0.45. The second clustering has 0 $pos_{between}$, 900 $pos_{within}$, 100 $neg_{within}$, and 0 $neg_{between}$, resulting in an unhappy score $U_2$ of 0.1. The distribution of positive and negative edges in this hypothetical signed Graph is imbalanced. Based on the unhappy scores, one might conclude that the second clustering is superior. A closer inspection reveals that the second clustering is trivial, as it assigns all vertices to one cluster. The first clustering, on the other hand, can correctly separate some of the negative edges across clusters and preserve some of the positive edges within clusters. Thus, the first clustering should be the optimal solution, which contradicts the unhappy ratio measure. The finding is analogous to the accuracy measure in a machine-learning setting when the trivial class is favored in binary classification.

On the other hand, measuring the summation of the fraction of positive edges within communities ($pos_{in}$) and the fraction of negative edges ($neg_{out}$) captures the clustering quality well for Figure~\ref{fig-example_unhappy}, \cite{2022Survey}. The unhappy score for both clustering assignments is the same (0.25) even though the left assignment did not account for \emph{any} negative edges while the right Figure accounted for both types of edges. In our proposed measurement, the left has a summation of 1.0, whereas the right has a summation of 1.71, which reflects the true clustering quality. n this work, we redefine the \emph{unhappy ratio} to count for \emph{both} positive and negative edges as: 
\begin{equation}
U_{ij} = \frac{pos_{between}}{pos_{between}+pos_{within}}+\frac{neg_{within}}{neg_{within}+neg_{between}}
\end{equation}

Our goal is to minimize the new \emph{unhappy ratio}, that is, the loss measure for a signed graph $G_i$ and clustering algorithm $j$. We rewrite it as a loss function, as our objective in clustering is now to minimize $\mathcal{L}(G_{ij})$ by splitting nodes into communities. We define new $pos_{out}$ and $neg_{in}$ as
\begin{equation}
    pos_{out}=\frac{pos_{between}}{pos_{between}+pos_{within}}
    \label{eq-PosOut}
\end{equation}
\begin{equation}
 neg_{in}=\frac{neg_{within}}{neg_{within}+neg_{between}}
   \label{eq-NegIn} 
\end{equation}
Thus, we propose to minimize the fraction of violating negative edges $neg_{in}(G_{ij})$ as well as the fraction of violating positive edges $pos_{out}(G_{ij})$ simultaneously. e define the violating edges in this context as the total number of positive edges between clusters and negative edges inside them.
\begin{equation}
U_{ij} = \mathcal{L}_{G_{ij}}=pos_{out}+neg_{in}
\label{eq-UnPlus}
\end{equation}

Symmetrically, we redefine $pos_{in}$ (Eq.~\ref{eq-PosIn}) and $neg_{out}$ (Eq.~\ref{eq-NegOut}) measures in terms of fractions to account for the positive and negative edge imbalance. 
\begin{equation}
 pos_{in}= \frac{pos_{within}}{pos_{between}+pos_{within}}
   \label{eq-PosIn} 
\end{equation}
\begin{equation}
neg_{out}= \frac{neg_{between}}{neg_{within}+neg_{between}}
   \label{eq-NegOut} 
\end{equation}

Next, we generalize the loss function to accommodate for the graph characteristics:
\begin{equation}
\label{eq-Loss}
\mathcal{L}_{G_{ij}}(\alpha,\beta)=\beta(\alpha{pos}_{out}+(1-\alpha){neg}_{in})+(1-\beta)*\frac{|V_{iso}|}{|V|} 
\end{equation}

\noindent The $\alpha$ controls the importance between ${pos}_{out}$ and ${neg}_{in}$. Setting $\alpha = $0.5 gives equal importance to both. e $\beta$ parameter controls the fraction of isolated vertices $|V_{iso}|$ produced in the process; |V| is the total number of vertices in the graph. f $\beta = 0$, then the algorithm will completely ignore minimizing the ${pos}_{out}$ and ${neg}_{in}$ and will find the cuts that yield the least amount of isolated vertices possible. ote that $\mathcal{L}_{G_{ij}}$ in Eq.~\ref{eq-UnPlus} is equal to $\mathcal{L}_{G_{ij}}(0.5,1)$ in  Eq.~\ref{eq-Loss}. 

\section{GraphC Methodology}
\label{sec-GraphC}

In Section~\ref{sec-Duality}, we have shown that the Laplacian matrices of balanced signed graphs of the same underlying Graph are isospectral and that a Harary cut can be performed through a spectral approach. The proposed \emph{GraphC} approach searches for the best Harary cut based on a quality measure \ref{eq-Loss} and a set of stopping criteria to automatically halt the algorithm execution to return the clustering labels of each node. Figure~\ref{fig-pipeline} illustrates the flow of the \emph{GraphC} algorithm. First, a signed network might contain several initial connected components. We start by labeling all vertices that are in the same connected component with the same label to produce an initial clustering label assignment set $\mathcal{C}$ as shown in Algorithm~\ref{alg-label}. Isolated vertices acquire unique labels. For two isolated nodes, the algorithm assigns different labels to each node. ore specifically, the algorithm first checks if the connected component at hand is in a set called `processed.` Then, it restores the original signs using the original signed network if it isn't in that set. Next, it checks if it has surpassed the time limit and ensures that the size of this connected component is more significant than $Gamma$. After the algorithm finds the best Harary cuts based on the loss function defined in Eq.~\ref{eq-Loss}, it checks whether the Harary split improves the overall quality of the clustering assignments according to Eq.~\ref{eq-overall_loss}. Finally, the algorithm commits that split if it leads to an improvement greater than $\epsilon$.

\begin{figure*}[!ht]
    \centering
    \includegraphics[scale=0.3]{new_pipeline2.pdf}
    \caption{The \emph{GraphC} pipeline: the starting state is "Connected component in set processed?" block.}
    \label{fig-pipeline}
\end{figure*} 

\begin{algorithm}[!ht]
\SetAlFnt{\small\sf}
\SetAlgoLined
\caption{Split and Label Components}\label{alg-label}
\KwData{$G_{ij}$, label\_counter}
\KwResult{Clustering label assignment set $\mathcal{C} = \{C_v\}, v \in V$}
label\_counter=$0$\;
\For{$CC$, $CC \in G_{ij}$}{
    \For{ $v$, $v \in CC$}{
        ${C_v}$=label\_counter\;
    }
    label\_counter++\;
}
\end{algorithm}

\noindent \textbf{Selecting the Best Harary Cut}
We use GraphB+ to create several stable states and perform Harary cuts. To find the best Harary cut, we pick the one that results in the slightest loss, as defined in Equation \ref{eq-Loss}. After selecting the Harary cut, we employ the Depth-First Search (DFS) to create the connected components. BFS starts at the root vertex and explores each branch as far as possible before backtracking. t continues this process until it has visited all vertices connected to the root vertex. The time it takes for DFS to run is proportional to the number of vertices ($|V|$) plus the number of edges ($|E|$). Algorithm~\ref{alg-bestsplit} demonstrates the process of selecting the best Harary cut. 


\begin{algorithm}[!ht]
\SetAlFnt{\small\sf}
\SetAlgoLined
\caption{Best Harary Cut}
\label{alg-bestsplit}
\KwData{$G_{ij}$, Set R, label\_selected, $\mathcal{C}$, $\alpha$, $\beta$, $I$}
\KwResult{$G^{FC}$}
\For{every vertex $v$ $in$ $G_{ij}$}{
\If{$C_v \neq $ label\_selected}{
 R = R + $v$ \;
}
}
$ G^{F} = G \setminus R $\; 
$G'=$GraphBplus($G^F,I$) \; 
$G^{FC} = G' | \{min \mathcal{L}_{\alpha,\beta,G^F}\}$\;
\end{algorithm}

\noindent \textbf{Stopping Criteria:} After finding the best Harary cut of a particular connected component, the algorithm will compute the overall quality of the new clusters of the entire signed network, which is similar to Equation~\ref{eq-Loss} and it is as follows: \begin{equation}
\label{eq-overall_loss}
\mathcal{L}_{G_{ij}}^{t}=({pos}_{out}+{neg}_{in})
\end{equation} Suppose the new clusters yield an improvement less than $\epsilon$, which is also predefined (similar to the condition k-means++'s stopping case). In that case, the algorithm is going to undo the last split of that connected component and add that connected component into a set called $processed$ such that if the algorithm iterates again to look for other connected components to split, whether they are newly formed or not, the algorithm is going to ignore any connected components that are in set $processed$. The algorithm is going to restore the original signs of the target-connected component before being fed to GraphB+. On the other hand, if it leads to an improvement of more than $\epsilon$, then the algorithm will commit the changes and proceed to the next eligible connected component. Algorithm~\ref{alg-community} demonstrates the entire algorithm execution. The $t_l$ variable is an optional time limit for the algorithm to execute. Note that setting the time limit as -1 means that the algorithm can execute for unlimited time as long as other stopping criteria have not been triggered.
\begin{algorithm}[!ht]
\SetAlgoLined
\caption{Choose component to split}\label{alg-community}
\label{alg-hararysplit}
\KwData{Signed graph $G_{ij}$, spanning trees sampling method $M$, $I$, $\alpha$, $\beta$, $\epsilon$, $Gamma$, Time limit $t_l$}
\KwResult{Clustering label assignment set $\mathcal{C} = \{C_v\}, v \in V$}
label\_counter=$0$\;
Call Alg.~\ref{alg-label} with inputs
$G,label\_counter,\mathcal{C}$\;
set R = $\emptyset$, processed = $\emptyset$\;
\While{true}{
\If{$ t \geq t_l$}{
break\;
}
label\_selected=-1 \;
terminate=true \;
\For{label $l, l \in \mathcal{C}$}{
\If{$|CC_l| \leq {Gamma}$}{
continue\;
}
\If{$l$ is not in set processed}{
label\_selected=$l$\;
terminate = false\;
}
}
\If{terminate = true}{
break\;
}
$\mathcal{C}_t = \mathcal{C}$\;
label\_counter\_temp = label\_counter \;
$G^{FC}=$ Call Alg.~\ref{alg-bestsplit} ($G_{ij}$, Set R,label\_selected, $\mathcal{C}$,$\alpha$, $\beta$, $I$)\;
\For{$ CC \in G^{FC}$ }{
\For{vertex $i \in CC$}{
$\mathcal{C_i}$=label\_counter\;
}
label\_counter++\;
}
Compute $\mathcal{U}_{t+1,G}$ \;
\If{$\mathcal{U}_{t,G}-\mathcal{U}_{t+1,G} \leq \epsilon $}{
$\mathcal{C} = \mathcal{C}_t$\;
label\_counter = label\_counter\_temp\;
Append label\_selected to processed\;
break\;
}
Set $\mathcal{U}_{t,G} = \mathcal{U}_{t+1,G}$ \;
$R = \emptyset$ \;}
\end{algorithm}

\textbf{Diminishing Returns (Fostering Scalability):} An intrinsic phenomenon in hierarchical clustering algorithms is that the deeper we go, the fewer potential improvements we get. Finding the best Harary cut of every connected component is computationally expensive, especially on massive signed graphs, as they might have millions of relatively small connected components, which could potentially yield marginal improvements, if any at all. The finding justifies the use of the $Gamma$ optional parameter to save computation. It represents a trade-off between efficiency and performance. If a connected component's size is less than $Gamma$, the algorithm is going to ignore that component and will not find the best Harary cut even if it is not in set $processed$. Figure~\ref{fig-exec} illustrates a typical execution of the algorithm on the PPI signed Graph, and it shows the gradual decreasing improvements over each Harary split. The overall improvement started from around 0.7 to a meager 0.0007 in the 5th Harary cut. 


\textbf{Illustrative Execution on Highland Tribes}
Figure~\ref{fig-Highland} shows the execution of our proposed algorithm. Assume that $I=$ 1000, $\alpha=$ 0.5 and $\beta=$ 1, $Gamma=$ 2, $\epsilon=$ 0.00000001, and $t_l=$ -1. First, the algorithm checks if it exceeded the time limit $t_l$; it proceeds since there is no time limit. The algorithm will check whether the initial component at level 0 is in $processed$; it proceeds to the next step because the $processed$ set is empty initially. t restores the original signs and finds the best Harary cut for this component. This will result in two connected components at level 1. The same above steps are repeated for both components. The component on the left at level 0 will trigger a stopping criterion, which is when the improvement is less than $epsilon$ after performing the Harary split. The algorithm will undo the split and commit the connected component with a red dashed circle, and the vertices within that component will be given a unique final label. Eventually, the two components at level 1 will also trigger the same stopping criteria, resulting in 3 clusters.
\begin{figure}[!ht]
    \centering
    \includegraphics[width=3.5in]{harary_highland.pdf}
    \caption{The execution of the \emph{GraphC} algorithm on a Highland signed graph comprising 16 vertices and 58 edges.}
    \label{fig-Highland}
\end{figure}
\section{Proof of Concept Implementation}
\subsection{Baselines}
For comparing the performance of our proposed algorithm, we use ten baselines, and they are as follows:
\begin{itemize}
    \item \textbf{Laplacian\_none} \cite{knyazev2017signed}: spectral clustering using the signed graph Laplacian.
    \item \textbf{Laplacian\_sym} \cite{knyazev2017signed}: spectral clustering using the symmetric Laplacian.
    \item \textbf{BNC\_none} \cite{2012chiang}: balanced normalized cuts.
    \item \textbf{BNC\_sym} \cite{2012chiang}: symmetric balanced normalized cuts.
    \item \textbf{SPONGE\_none} \cite{pmlr-v89-cucuringu19a}: baseline SPONGE implementation.
    \item \textbf{SPONGE\_sym} \cite{pmlr-v89-cucuringu19a}: symmetric SPONGE implementation.
    \item \textbf{Hessian} \cite{Saade2014SpectralCO}: clustering based on signed Bethe Hessian.
    \item \textbf{A\_sym} \cite{signet_repo}: spectral clustering using symmetric adjacency matrix.
    \item \textbf{dns} \cite{snsdns}: clusters the Graph using eigenvectors of the bns Laplacian matrix.
    \item \textbf{sns} \cite{snsdns}: clusters the Graph using eigenvectors of the sns Laplacian matrix.

\end{itemize}

\subsection{Implementation}
The proposed algorithm's implementation is in C++. The algorithm automatically discovers optimal communities without a predefined number of clusters $k$. t finds and commits the optimal Harary cut for each connected component if it satisfies the following conditions: it is not in set $processed$, did not exceed the time limit $t_l$, its size is more significant than $Gamma$, that Harary cut leads to an improvement greater than $\epsilon$. The parameters used for all Konect signed graphs across the board are $I =$ 1000, $\alpha =$ 0.5, $\beta =$ 1, $\epsilon =$ 0.00000001, $Gamma =$ 2, and $t_l =$ 100000 except WikiConflict and WikiPolitics where $Gamma =$ 10 to speed up the execution. The implementation of the baseline methods is in Python. We run the kmeans++ clusters the corresponding matrices with $n\_init =$10. The $n\_init$ is the number of times the k-means++ algorithm runs with different centroid seeds. The SigNet \cite{signet_repo} with $k$ parameter chosen based on two recent research papers \cite{he2022sssnetsemisupervisedsignednetwork, 2022Survey} is run as a baseline, as defined in Table~\ref{tab-konectData}. If a signed graph does not have a known used $k$ hyperparameter in the literature, we assigned a $k$ to it that is equal to the $k$ (known) of the most similar signed Graph in terms of size. For all signed graphs, preprocessing purges self-edges, inconsistent edges, and duplicate edges (first kept), and the neutral edges are considered the positive edges. The parameters used for all Amazon signed graphs across the board are $I =$ 50, $\alpha =$ 0.5, $\beta =$ 1, $\epsilon =$ 0.00000001, and $Gamma =$ 40, $t_l =$ -1. The code for running the baselines and the implementation of our algorithm is available in \url{https://anonymous.4open.science/r/graphC-2046/}. 

\subsection{Setup}
The operating system used for the experiments is Linux Ubuntu 20.04.3, running on the 11th Gen Intel(R) Core(TM) i9-11900K @ 3.50GHz with 16 physical cores. It has one socket, two threads per core, and eight cores per socket. The architecture is X86\_x64. The GPU is Nvidia GeForce RTX 3070 and has 8GB of memory. Its driver version is 495.29.05, and the CUDA version is 11.5. The cache configuration is L1d : 384 KiB, L1i : 256 KiB, L2 : 4 MiB, L3 : 16 MiB. The CPU op is 32-bit and 64-bit.

\subsection{Signed Graph Datasets}
Konect and other signed graphs and their characteristics are described in Table~\ref{tab-konectData}. \emph{Highland} is the signed social network of tribes of the Gahuku\-Gama alliance structure of the Eastern Central Highlands of New Guinea, from Kenneth Read \cite{konect}. \emph{Sampson25}, which models sentiment over time between novice monks in a New England monastery captured by Sampson \cite{1968Sampson}. \emph{Congress} is a signed network where vertices are politicians speaking in the United States Congress, and a directed edge denotes that a speaker mentions another speaker \cite{konect}. In the \emph{Chess} network, each vertex is a chess player, and a directed edge represents a game with the white player having an outgoing edge and the black player having an ingoing edge. The weight of the edge represents the outcome \cite{konect}. \emph{BitcoinAlpha} is a user-user trust/distrust network from the Bitcoin Alpha platform for trading bitcoins \cite{konect}. \emph{BitcoinOTC} is a user-user trust/distrust network from the Bitcoin OTC platform for trading Bitcoins \cite{konect}. \emph{TwitterRef} captures data from Twitter concerning the 2016 Italian Referendum. Different stances between users signify a negative tie, while the same stances indicate a positive link \cite{Lai2018}. \emph{WikiElec} is the network of users from the English Wikipedia that voted for and against each other in admin elections \cite{konect}. \emph{SlashdotZoo} is the reply network of the technology website Slashdot. Vertices are users, and edges are replies \cite{konect}. The edges of \emph{WikiConflict} represent positive and negative conflicts between users of the English Wikipedia \cite{konect}. \emph{WikiPolitics} is an undirected signed network that contains interactions between the users of the English Wikipedia that have edited pages about politics. Each interaction, such as text editing and votes, is given a positive or negative value \cite{konect}. \emph{Epinions} is the trust and distrust network of Epinions, an online product rating site. It incorporates individual users connected by directed trust and distrust links \cite{konect}. 

Table~\ref{tab-konectData} lists the characteristics of the Konect signed graphs. \emph{PPI} models the protein-protein interaction network \cite{he2022sssnetsemisupervisedsignednetwork}. \emph{WikiRfa} describes voting information for electing Wikipedia managers \cite{he2022sssnetsemisupervisedsignednetwork}.

Amazon dataset consists of \emph{seventeen} signed graphs derived from the Amazon rating and review files \cite{2016Amazon2}. The dataset contains product reviews and metadata from Amazon, spanning May 1996 to July 2014. Rating score is mapped into an edge between the user and the product as follows $(5,4) \rightarrow m^+$, $3 \rightarrow m$ (no sign), and $(2, 1) \rightarrow m^-$ \cite{2016Amazon2}. Table~\ref{tab-amazonData} outlines the characteristics of the most significant connected component. For example, clustering a bipartite graph of users and items in a recommendation system context can reveal groups of users who have similar preferences, as well as groups of items that are popular among certain types of users. Another example is clustering a bipartite graph of authors and papers, which can identify research communities and topics.

\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.75]{ppi_new.pdf}
    \caption{Example output of the overall improvements with each \textbf{committed} Harary split of every connected component of our proposed algorithm on PPI signed graph.}
    \label{fig-exec}
\end{figure}

\section{Konect Signed Graphs Experiment}

\begin{table}[!ht]
\setlength\tabcolsep{0.2pt}
\centering\footnotesize
\caption{Konect + benchmark: Konect \cite{konect} plus TwitterReferendum \cite{Lai2018}, PPI \cite{he2022sssnetsemisupervisedsignednetwork}, and WikiRfa \cite{he2022sssnetsemisupervisedsignednetwork} signed graphs. LCC stands for the largest connected component, $k$ is the predefined number of clusters for spectral clustering methods, and \emph{GraphC} results include the resulting number of clusters with more or equal to 5 elements as well as clusters with less than f ve elements. The last column is the number of splits produced after the algorithm's execution.}
\label{tab-konectData}
\begin{tabular}{l||r|c||r||r|r|r}
 & \multicolumn{2}{c||} {\bf LCC} & \multicolumn{1}{c||} {\bf $k$} & \multicolumn{3}{c}{GraphC}  \\ 
\bf Dataset &\# \bf vertices&\# \bf edges&\# \bf clusters & \# \bf clusters$\geq$5  & \# \bf clusters$<$5&\# \bf splits \\ \hline \hline
\emph{Highland}& 16 & 58 & 3 & 1 & 2& 2\\  \hline
\emph{Sampson25}& 25 & 165 & 4 & 2 & 2& 3\\  \hline
\emph{Congress}& 219 & 521 & 11 & 2 &9 & 3\\  \hline
\emph{PPI}& 3,058 & 11,860 & 10 & 29 & 887 &16\\  \hline
\emph{BitcoinAlpha} & 3,775 &14,120 & 10 & 14 & 201 &17\\  \hline
\emph{BitcoinOTC}& 5,875 & 21,489& 20 & 22 & 518 &10\\  \hline
\emph{Chess}& 7,115 & 55,779& 30 & 46 & 1,014&41\\  \hline
\emph{TwitterRef}& 10,864& 251,396& 50 & 4 &234 &8 \\  \hline
\emph{SlashdotZoo}& 79,116 &467,731 & 100 & 245 &14,603 &53\\ \hline
\emph{Epinions}& 119,130 & 704,267& 100 & 584 &27,498 &237\\ \hline
\emph{WikiRfa}&7,634& 175,787 &30 & 25 & 1,419&24\\  \hline
\emph{WikiElec}&7,066& 100,667& 30 & 38 & 1,528 &25\\  \hline
\emph{WikiConflict}& 113,123 &2,025,910 & 100  & 208 &66,083 &32\\  \hline
\emph{WikiPolitics}& 137,740 & 715,334 & 100 & 875 & 18,964&89 \\ 
\end{tabular}
\end{table}

The number of edges of the most significant connected component is computed locally in our machine using preprocessing techniques such as removing duplicate and inconsistent edges. Our algorithm also detects the number of clusters (including isolated vertices) and the number of Harary split operations executed for various signed networks. 

\begin{sidewaystable}[!ht]
\setlength\tabcolsep{0.5pt}
\centering %\footnotesize
\caption{Evaluation results of our proposed algorithm against ten different baselines on 14 datasets in terms of ${pos}_{in}(G)$ and ${neg}_{out}(G)$, and time in seconds  The empty cell indicates the method failed to run on the dataset. \textunderscore{Best} results are underscored. Graphic finds a clustering that consistently achieves a good compromise between ${pos}_{in}(G)$ and ${neg}_{out}(G)$ (pos and neg in this table as percentages) on the Konect dataset with \textbf{both} having high values unlike other baselines where they fail or solely focus on either evaluation metric.}
\label{tab-results}
%\resizebox{2.05\columnwidth}{!}{
\begin{tabular}{l||c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
\textbf{} & \multicolumn{3}{c|}{\emph{GraphC}} & \multicolumn{3}{c|}{\textbf{Hessian}} & \multicolumn{3}{c|}{\textbf{$\mathbf{A_{sym}}$}} & \multicolumn{3}{c|}{\textbf{$\mathbf{L_{none}}$}} & \multicolumn{3}{c|}{\textbf{$\mathbf{L_{sym}}$}} & \multicolumn{3}{c|}{\textbf{$\mathbf{BNC_{none}}$}} & \multicolumn{3}{c|}{\textbf{$\mathbf{BNC_{sym}}$}} & \multicolumn{3}{c|}{\textbf{$\mathbf{SPO_{none}}$}} & \multicolumn{3}{c|}{\textbf{$\mathbf{SPO_{sym}}$}} & \multicolumn{3}{c|}{\textbf{dns}} & \multicolumn{3}{c}{\textbf{sns}} \\\hline
\textbf{Dataset} & \textbf{pos} & \textbf{neg} & \textbf{t}  & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} & \textbf{pos} & \textbf{neg} & \textbf{t} \\\hline

\textbf{Highland} & {\ul \textbf{93}} & {\ul \textbf{100}} & 0.1  & {\ul 93} & {\ul 100} & 0.2 & {\ul 93} & {\ul 100} & 0.1 & {\ul 93} & {\ul 100} & 0.1 & {\ul 93} & {\ul 100} & 0.1 & {\ul 93} & {\ul 100} & 0.1 & {\ul 93} & {\ul 100} & 0.1 & {\ul 93} & {\ul 100} & 0.19 & {\ul 93} & {\ul 100} & 0.17 & {\ul 93} & {\ul 100} & 0.2 & {\ul 93} & {\ul 1} & 0.1 \\ \hline

\textbf{Sampson25} & {\ul \textbf{70}} & {\ul \textbf{90}} & 0.2 & 63 & 93 & 0.07 & 60 & 91 & 0.04 & 59 & 79 & 0.1 &63 & 92 & 0.03 & 78 & 65 & 0.03 & 62 & 91 & 0.04 & 63 & 92 & 0.04 & 64 & 92 & 0.04 & 70 & 85 & 0.03 & 70 & 82 & 0.03 \\\hline

\textbf{Congress} & {\ul \textbf{93}} & {\ul \textbf{100}} & 0.77 & 62 & 100 & 0.11 & 70 & 100 & 0.11 & 86 & 97 & 0.12 & 24 & 100 & 0.11 & 39 & 77 & 0.13 & 93 & 97 & 0.14 & 70 & 84 & 0.14 & 67 & 100 & 0.12 & 94 & 95 & 0.12 & 98 & 33 & 0.12 \\ \hline

\textbf{PPI} & {\ul \textbf{81}} & {\ul \textbf{98}} & 9 & 79 & 35 & 1 & 100 & 2 & 1 & 100 & 0.87 & 1 & 100 & 0.98 & 1 & 93 & 10 & 1 & 100 & 0.98 & 1 & 100 & 0.1 & 1 & 100 & 1 & 1 & 100 & 0.72 & 1 & 100 & 0.77 & 1 \\ \hline

\textbf{BitcoinAlpha} & {\ul \textbf{81}} & {\ul \textbf{86}} & 14 & 37 & 89 & 2 & 100 & 0.5 & 2 & 30 & 68 & 3 & 72 & 24 & 3 & 55 & 66 & 2 & 100 & 3 & 2 & 91 & 3 & 3 & 100 & 5 & 3 & 100 & 4 & 2 & 100 & 7 & 2 \\\hline

\textbf{BitcoinOTC} & {\ul \textbf{82}} & {\ul \textbf{90}} & 22 & 30 & 94 & 4 & 71 & 42 & 4 & 21 & 80 & 7 & 61 & 43 & 4 & 86 & 61 & 4 & 100 & 35 & 4 & 62 & 30 & 8 & 100 & 28 & 4 & 100 & 8 & 4 & 100 & 8 & 4 \\ \hline

\textbf{Chess} & {\ul \textbf{39}} & {\ul \textbf{84}} & 45  & 40 & 70 & 7 & 100 & 0.17 & 7 &  &  &  &  &  &  & 65 & 34 & 7 & 100 & 0.21 & 7 & 100 & 0 & 12 & 100 & 0.51 & 8 & 100 & 0.2 & 7 & 100 & 0.2 & 7 \\ \hline

\textbf{TwitterRef} & {\ul \textbf{89}} & {\ul \textbf{100}} & 446  & 11 & 98 & 31 & 65 & 90 & 31 & &  &  & 67 & 94 & 31 & 23 & 93 & 30 & 100 & 0.66 & 31 & 97 & 4 & 60 & 65 & 94 & 31 & 100 & 0.6 & 30 & 100 & 0.55 & 31 \\ \hline

\textbf{SlashdotZoo} & {\ul \textbf{69}} & {\ul \textbf{86}} & 716  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & &  & &  &  &  &  &  &  &  &  &  \\\hline

\textbf{Epinions} & {\ul \textbf{80}} & {\ul \textbf{88}} & 2094 &  &  &  &  &  &  &  &  &  &  &  &  &  & &  &  &  & &  &  &  &  &  &  &  &  &  &  &  &  \\\hline

\textbf{WikiRfa} & {\ul \textbf{61}} & {\ul \textbf{81}} & 83 & 54 & 59 & 18 & 79 & 30 & 18 & 100 & 0.003 & 19 & 74 & 35 & 18 & 100 & 2 & 18 & 100 & 0.01 & 18 & 9 & 11 & 2 & 91 & 6 & 19 & 100 & 0.02 & 18 & 100 & 0.01 & 18 \\ \hline

\textbf{WikiElec} & {\ul \textbf{70}} & {\ul \textbf{79}} & 60 & 19 & 92 & 11 & 61 & 65 & 11 & 100 & 0.05 & 21 & 100 & 0.05 & 11 & 51 & 58 & 11 & 1 & 0.11 & 11 & 92 & 12 & 20 & 1 & 0.74 & 11 & 1 & 0.17 & 11 & 1 & 0.16 & 11 \\ \hline

\textbf{WikiConflict} & {\ul \textbf{94}} & {\ul \textbf{86}} & 1235 &  &  & & &  &  & &  &  &  & & & &  &  & &  &  &  &  &  & &  &  & & & &  &  & \\\hline

\textbf{WikiPolitics} & {\ul \textbf{82}} & {\ul \textbf{85}} & 1279 &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  & &  & &  &  &  &  &  &  &  &  &  \\


\end{tabular}
%}
\end{sidewaystable}


The algorithms are evaluated using $pos_{in}$ and $neg_{out}$, which are the fraction of positive edges that are within communities and the fraction of opposing edges that are between communities  First, we intend to observe and visualize the effect of increasing the number of subsequent Harary splits (that cause an overall improvement in Equation~\ref{eq-overall_loss}) on the two evaluation metrics  Figure~\ref{fig-wikielections} represents the execution of our algorithm on the WikiElec signed Graph  Initially, $pos_{in} =$  1.0, $neg_{out} =$ 0.0 because all edges are in one cluster  For each split, our algorithm cuts the connected component in a way that minimizes the $pos_{within}$ lost and maximizes the $neg_{between}$ gained.
Moreover, losing $pos_{within}$ with each split is inevitable  The rate of increase of $neg_{between}$ is far greater than the rate of decrease of $pos_{within}$ edges during the splits from 1 to 10, leading to significant improvement in the overall quality of the clusters  Beyond ten cuts, the improvements reach an expected plateau where gradually decreasing improvements occur as a result of cutting more deeply into the connected components  This is where the optional $Gamma$ parameter comes into play, where we can prompt the algorithm to halt before or right at the plateau to save running time  Table~\ref{tab-konectData} presents the resultant number of clusters (including isolated vertices) detected as well as the number of Harary split operations executed for the benchmarks  It is noteworthy to mention that methods that possess the $k$ parameter usually fuse the supposedly isolated vertices into arbitrary clusters to comply with the restrictions of what the $k$ parameter imposes  However, our algorithm is able to freely separate the isolated vertices and detect as many clusters as possible as long as it yields an improvement more significant than $\epsilon$ in the overall value in Equation~\ref{eq-overall_loss}  Finally, the performance and execution time of our proposed algorithm are examined against ten baselines, as shown in Table~\ref{tab-results}  The empty values in some of the cells are inputted for two reasons  Either because the corresponding baseline took more than two days of execution or because some of the eigenvectors during the spectral decomposition did not converge, especially for large signed graphs, causing an error  In all tested signed graphs of diverse sizes and densities, our proposed algorithm achieves superior and greatest $pos_{in}$ and $neg_{out}$  While the proposed algorithm's execution time is more significant than some of the methods on some graphs, such as WikiElec, this is ascribed to the fact that the choice of $k$ in these methods is relatively small, which causes them to have a lower execution time.
Furthermore, these baselines swiftly deteriorate with increasing graph size and $k$ parameter, causing them to have a much longer execution time than our algorithm.

\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.65]{wikielec_graph-cropped.pdf}
    \caption{${pos}_{in}$ and ${neg}_{out}$ graph for WikiElec with each Harary split during the algorithm execution.}
     \label{fig-wikielections}
\end{figure}

\section{Amazon Ratings and Reviews Modeling}

Amazon ratings and reviews \cite{2016Amazon2} are mapped to signed graphs where edges are negative for 0,1,2 ratings, have no sign for three ratings, and have a plus sign for 4 and 5 ratings  We prove that our algorithm is capable of scaling to a signed network with millions of vertices and edges by running it on the Amazon signed graphs as in Table~\ref{tab-amazonData}  For instance, \emph{GraphC} successfully ran the most extensive Amazon graph (Book) with a reasonable amount of time, which is 31 hours with high  $pos_{in}$ and $neg_{out}$  Therefore, our algorithm is capable of detecting clusters automatically in a scalable fashion  In addition, from Table~\ref{tab-amazonData}, we can observe that the bipartite graph of Amazon reviews/ratings has a skewed distribution of vertices and edges, where most of the vertices are sparsely connected, and only a few vertices dominate the market  For instance, for the Books signed graph, about 1 million clusters contain less than five users/books, whereas a relatively meager 32 thousand clusters have more than five users/books  Although these clusters contain a mix of users and items and no quantification of the number of users each item has in its cluster is done, this may correlate with the "Long Tail Phenomenon" \cite{anderson2006long} where a large number of products or services that are not very popular can jointly have a significant share of the market that may overtake or be comparable to the concurrent bestsellers that are very successful. 

\begin{table*}[!ht]
\setlength\tabcolsep{2pt}
\centering %\footnotesize
        \caption{Amazon ratings and reviews \cite{2016Amazon2} mapped to signed graphs. \emph{GraphC} results include ${pos}_{in}(G)$ and ${neg}_{out}(G)$ (pos and neg in this table as percentages) and the resulting number of clusters with more or equal to 5 elements as well as clusters with less than five elements.}
    \label{tab-amazonData}
   \begin{tabular}{l||r|r|r|r|r|r|r|r}
         \bf Amazon & \multicolumn{2}{c||} {\bf LCC} & \multicolumn{6}{c} {\bf GraphC}\\ \hline \hline
        \bf Ratings & \bf \# vertices& \bf \# edges &\textbf{pos}& \textbf{neg}&\textbf{\# splits}& \textbf{time (s)} &  \# \bf clusters$\geq$5  & \# \bf clusters$<$5 \\ \hline
        Books & 9,973,735 & 22,268,630 & 73 & 86  & 22 &115,561 & 31,988& 1,003,734 \\ \hline
        Electronics & 4,523,296 & 7,734,582 &88 & 80  & 7 & 23,516 & 9,208 & 862,970 \\ \hline
        Jewelry & 3,796,967 & 5,484,633 & 81 & 90  &11  & 25,650 & 15,802 & 648,695 \\ \hline
        TV  & 2,236,744 & 4,573,784 & 74 & 87 &17 &19,019  & 4,456  & 281,653 \\ \hline
        Vinyl & 1,959,693 & 3,684,143 & 74 & 87   & 16& 16,420 & 5,718 & 169,493 \\ \hline
        Outdoors & 2,147,848 & 3,075,419& 92 &80   &15 &13,613 &12,294& 393,579 \\ \hline
        AndrApp & 1,373,018 & 2,631,009 &77 &  89 & 24 & 1,642 & 1,462 & 205,336 \\ \hline
        Games & 1,489,764 & 2,142,593 92 & 82  & 22 &1,662 & 280,356& 8,111& 272,245\\ \hline
        Automoto & 950,831 & 1,239,450&94&79 &  13 & 783 & 8,515&202,749  \\ \hline
        Garden& 735,815 & 939,679 & 93&85& 13   & 436 &4,636 & 153,452  \\ \hline
        Baby & 559,040 & 892,231&79 &  91&14 & 489 &  2,367 & 94,474 \\ \hline
        Music & 525,522 & 702,584& 87& 83  &23  &571& 6,124 & 109,287\\ \hline
        Video & 433,702 & 572,834 &85 &93&  14 & 364 &1,401 & 46,481 \\ \hline
        Instruments & 355,507 & 457,140 &90 &85  &15 & 281 & 3,536 & 61,964  \\ \hline 
        \hline
        \bf Reviews  & \bf \# vertices& \bf \# edges &\textbf{pos}& \textbf{neg}&\textbf{\# splits}& \textbf{time (s)} & \bf clusters$\geq$5  & \# \bf clusters$<$5 \\ \hline
        Core Music  & 9,109 & 64,706 &0.52 & 0.848   & 14 &  9.57& 38 &  746 \\ \hline
        Core Video& 6,815 & 37,126 &0.572 & 0.852  & 13 & 5.54& 26& 737  \\ \hline
        Core Instrum& 2,329 & 10,261& 0.510 &  0.928 & 8 &1.90& 20 & 159 \\ 
    \end{tabular}
\end{table*}

\subsection{Parameters Study \& Analysis}
\begin{figure*}[!ht]
    \centering
    \includegraphics[width=6.5in]{varying_gamma.pdf}
    \caption{The effect of varying $Gamma$ on the number of clusters, clustering quality, the execution time, and number of Harary splits on the Chess signed graph. The y-axis is ${pos}_{in}$ and ${neg}_{out}$ as in equations~\ref{eq-PosIn} and \ref{eq-NegOut} respectively, number of splits, execution time, and number o  communities for the four graphs respectively (from left to right). The x-axis is the $Gamma$ value. GraphC ignores the connected component of size less than $Gamma$.}
    \label{fig-gamma}
\end{figure*}
\begin{figure*}[!ht]
    \centering
    \includegraphics[width=6.5in]{varying_iter.pdf}
    \caption{The effect of varying $I$ (number of iterations per connected component) on the number of clusters, clustering quality, execution time, and number of Harary splits on the Chess signed graph. The y-axis is ${pos}_{in}$ and ${neg}_{out}$ as in equations~\ref{eq-PosIn} and \ref{eq-NegOut} respectively, number of splits, execution time, and number o  communities for the four graphs, respectively (from left to right). The x-axis is the $I$ value.}
    \label{fig-iter}
\end{figure*}
\begin{figure*}[!ht]
    \centering
    \includegraphics[width=6.5in]{varying_epsilon.pdf}
    \caption{The effect of varying $\epsilon$ on the number of clusters, clustering quality, execution time, and number of Harary splits on the Chess signed graph. From left to right, the y-axis is ${pos}_{in}$ and ${neg}_{out}$ as in equations~\ref{eq-PosIn} and \ref{eq-NegOut} respectively. For this experiment, use only the number of clusters larger than $1$ or $2$ if for Amazon. (The effect of varying $\epsilon$ on the number of clusters),  number of splits, execution time, and number of communities for the four graphs, respectively (from left to right).}
    \label{fig-epsilon}
\end{figure*}

In order to better understand the parameters $I$, $Gamma$, and $\epsilon$ and their effect on the clustering process, we run \emph{GraphC} on the Chess signed graph. First, we start by running the algorithm with $Gamma \in \{2, 1000, 2000, 2500, 3500\}$  with the other parameters fixed as $I=$ 50, $\alpha =$ 0.5, $\beta =$ 1, $\epsilon =$ 0.00000001, and $t_l =$ -1. As observed in the four graphs in Figure~\ref{fig-gamma}, increasing $Gamma$ deteriorates the clustering quality where the number of splits and the execution time decrease, resulting in a lower number of communities. The higher value of $Gamma$ means that the algorithm will disregard even larger connected components that have the potential to improve the overall quality of the clustering if split. In return, we save computational time because the algorithm won't search for the best split for a connected component of size smaller than $Gamma$. Second, we run the algorithm with $I \in \{1000, 800, 500, 50,10 \}$  with the other parameters fixed as $Gamma=$ 2, $\alpha =$ 0.5, $\beta =$ 1, $\epsilon =$ 0.00000001, and $t_l =$ -1. According to the four graphs in Figure~\ref{fig-iter}, decreasing the number of iterations for searching for the best Harary split for a connected component gradually degrades the overall quality of the clustering, reducing the execution time tremendously. On the other hand, the number of splits and clusters seems to stay the same or fluctuate around 41 splits and 1060 clusters. Finally, we run our algorithm with $\epsilon \in \{0.000000001, 0.0001, 0.01, 0.1,0.5 \}$  with the other parameters fixed as $Gamma=$ 2, $\alpha =$ 0.5, $\beta =$ 1, $I =$ 1000, and $t_l =$ -1. Increasing $\epsilon$ as observed by the last four graphs in Figure~\ref{fig-epsilon} discourages splits from taking place because there is a higher chance the overall improvement will be less than $\epsilon$ which prevents a cut, and more connected components will be added to the set $processed$. This naturally degrades the quality of the clustering process and further reduces the time taken by the algorithm execution. The number of clusters seems to be almost the same as when we varied $I$, fluctuating around 1060. Overall, we can deduce that in order to obtain the best possible clustering, one should increase $I$ and decrease $Gamma$ and $\epsilon$ as much as possible as long as the machine's resources can handle it regardless of the type, density, or size of the signed network.

\section{Conclusion}
The arrangement of communities within a network can unveil concealed insights into the connections and dynamic processes within intricate systems. The identification of communities is a widely utilized approach across various domains, ranging from biological to social networks, to extract valuable information. Recent studies have highlighted the challenge of restoring community structure in sparse networks using spectral methods. Current issues in signed graph clustering algorithms are choosing an appropriate number of clusters $k$, eigenvalue pollution, no scalability to large graphs, and the reliance on ground truth to perform clustering. For this, we take a different approach and propose a novel and scalable hierarchical clustering algorithm for a signed network capable of automatically detecting optimal clusters without a predefined $k$ using the GraphB+ algorithm. Our algorithm is also flexible in the sense that we can adjust the aforementioned optional parameters to achieve any desired outcome, such as controlling how many isolated vertices we want.
Moreover, we foster scalability by introducing the $Gamma$ optional parameter that acts as a trade-off between efficiency and scalability. We evaluated our proposed algorithm as well as baselines for the ${pos}_{in}$ and ${neg}_{out}$ metrics. Experimental results show that our algorithm achieves high values for these two metrics on all datasets across the board. In contrast, the baseline meth ds fails to scale or obtain a clustering assignment close to optimal. More work is needed to parallelize our algorithm further to achieve a substantial speedup. Exploring how we can take advantage of the proposed consensus features \cite{2021Cloud} in order to improve the overall quality of the clustering assignment is also an exciting route we want to take.

%\bibliographystyle{ametsoc}
%\bibliographystyle{apalike}
%\bibliography{Bib/graphB,Bib/DataLab,Bib/Datasets,Bib/TesicPub,Bib/graphC}

\begin{thebibliography}{}

\bibitem[Abelson and Rosenberg, 1958]{1958Abelson}
Abelson, R.~P. and Rosenberg, M.~J. (1958).
\newblock Symbolic psycho-logic: A model of attitudinal cognition.
\newblock {\em Behavioral Science}, 3(1):1--13.

\bibitem[Amelkin and Singh, 2019]{amelkin2019fighting}
Amelkin, V. and Singh, A.~K. (2019).
\newblock Fighting opinion control in social networks via link recommendation.
\newblock In {\em Proceedings of the 25th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, KDD '19, page 677685, New York,
  NY, USA. Association for Computing Machinery.

\bibitem[Anderson, 2006]{anderson2006long}
Anderson, C. (2006).
\newblock {\em The Long Tail: Why the Future of Business Is Selling Less of
  More}.
\newblock Hyperion.

\bibitem[Boulton, 2016]{BOULTON20161}
Boulton, L. (2016).
\newblock Spectral pollution and eigenvalue bounds.
\newblock {\em Applied Numerical Mathematics}, 99:1--23.

\bibitem[Cartwright and Harary, 1956]{Har2}
Cartwright, D. and Harary, F. (1956).
\newblock Structural balance: a generalization of {H}eider's theory.
\newblock {\em Psychological Rev.}, 63:277--293.

\bibitem[Chen et~al., 2018a]{OHSachs}
Chen, G., Liu, V., Robinson, E., Rusnak, L.~J., and Wang, K. (2018a).
\newblock A characterization of oriented hypergraphic laplacian and adjacency
  matrix coefficients.
\newblock {\em Linear Algebra and its Applications}, 556:323 -- 341.

\bibitem[Chen et~al., 2018b]{bridge}
Chen, Y., Qian, T., Liu, H., and Sun, K. (2018b).
\newblock "bridge": Enhanced signed directed network embedding.
\newblock In {\em Proceedings of the 27th ACM International Conference on
  Information and Knowledge Management}, CIKM '18, pages 773--782, New York,
  NY, USA. Association for Computing Machinery.

\bibitem[Chiang et~al., 2012]{2012chiang}
Chiang, K.-Y., Whang, J.~J., and Dhillon, I.~S. (2012).
\newblock Scalable clustering of signed networks using balance normalized cut.
\newblock {\em Proceedings of the 21st ACM international conference on
  Information and Knowledge Management}, pages 615 -- 624.

\bibitem[Cucuringu et~al., 2019a]{signet_repo}
Cucuringu, M., Davies, P., Glielmo, A., and Tyagi, H. (2019a).
\newblock {\em SigNet}.

\bibitem[Cucuringu et~al., 2019b]{pmlr-v89-cucuringu19a}
Cucuringu, M., Davies, P., Glielmo, A., and Tyagi, H. (2019b).
\newblock Sponge: A generalized eigenproblem for clustering signed networks.
\newblock In Chaudhuri, K. and Sugiyama, M., editors, {\em Proceedings of the
  Twenty-Second International Conference on Artificial Intelligence and
  Statistics}, volume~89 of {\em Proceedings of Machine Learning Research},
  pages 1088--1098. PMLR.

\bibitem[Cucuringu et~al., 2021]{2021cucuringu}
Cucuringu, M., Singh, A.~V., Sulem, D., and Tyagi, H. (2021).
\newblock Regularized spectral methods for clustering signed networks.
\newblock {\em Journal of Machine Learning Research}, 22(264):1--79.

\bibitem[Derr et~al., 2018]{convsigned}
Derr, T., Ma, Y., and Tang, J. (2018).
\newblock Signed graph convolutional network.
\newblock {\em CoRR}, abs/1808.06354.

\bibitem[Derr et~al., 2020]{derr2020link}
Derr, T., Wang, Z., Dacon, J., and Tang, J. (2020).
\newblock Link and interaction polarity predictions in signed networks.
\newblock {\em Social Network Analysis and Mining}, 10(1):1--14.

\bibitem[Donath and Hoffman, 1973]{donath}
Donath, W.~E. and Hoffman, A.~J. (1973).
\newblock Lower bounds for the partitioning of graphs.
\newblock {\em IBM Journal of Research and Development}, 17(5):420--425.

\bibitem[\emph{Ghadeer Alabandi} et~al., 2021]{2021Alabandi}
\emph{Ghadeer Alabandi}, {\bf Jelena Te\v{s}i\'{c}}, Rusnak, L., and Burtscher,
  M. (2021).
\newblock Discovering and balancing fundamental cycles in large signed graphs.
\newblock In {\em Proceedings of the International Conference for High
  Performance Computing, Networking, Storage and Analysis}, SC '21, New York,
  NY, USA. Association for Computing Machinery.

\bibitem[\emph{Maria Tomasso} et~al., 2022a]{2022Survey}
\emph{Maria Tomasso}, Rusnak, L., and {\bf Jelena Te\v{s}i\'{c}} (2022a).
\newblock Advances in scaling community discovery methods for signed graph
  networks.
\newblock {\em Oxford Journal of Complex Networks}, 10(3).

\bibitem[\emph{Maria Tomasso} et~al., 2022b]{2022Cluster}
\emph{Maria Tomasso}, Rusnak, L., and {\bf Jelena Te\v{s}i\'{c}} (2022b).
\newblock Cluster boosting and data discovery in social networks.
\newblock In {\em Proceedings of the 37th ACM/SIGAPP Symposium On Applied
  Computing (SAC)}.

\bibitem[et~al., 2018]{aldogl2018}
et al., M.~O. (2018).
\newblock Initial release of the signet package.

\bibitem[Garimella et~al., 2021]{garimella2021political}
Garimella, K., Smith, T., Weiss, R., and West, R. (2021).
\newblock Political polarization in online news consumption.
\newblock In {\em Proceedings of the International AAAI Conference on Web and
  Social Media}, volume~15, pages 152--162.

\bibitem[Gholami et~al., 2024]{overlapping}
Gholami, M., Sheikhahmadi, A., Khamforoosh, K., Jalili, M., and Veisi, F.
  (2024).
\newblock {A new approach to finding overlapping community structure in signed
  networks based on Neutrosophic theory}.
\newblock {\em Journal of Complex Networks}, 12(1):cnad051.

\bibitem[Harary and Cartwright, 1968]{Harary1968}
Harary, F. and Cartwright, D. (1968).
\newblock On the coloring of signed graphs.
\newblock {\em Elemente der Mathematik}, 23:85--89.

\bibitem[He and McAuley, 2016]{2016Amazon2}
He, R. and McAuley, J. (2016).
\newblock Ups and downs: Modeling the visual evolution of fashion trends with
  one-class collaborative filtering.
\newblock In {\em Proceedings of the 25th International Conference on WWW},
  pages 507--517.

\bibitem[He et~al., 2022]{he2022sssnetsemisupervisedsignednetwork}
He, Y., Reinert, G., Wang, S., and Cucuringu, M. (2022).
\newblock Sssnet: Semi-supervised signed network clustering.

\bibitem[Interian et~al., 2022]{interian2022network}
Interian, R., Marzo, R.~G., Mendoza, I., and Ribeiro, C.~C. (2022).
\newblock Network polarization, filter bubbles, and echo chambers: An annotated
  review of measures, models, and case studies.
\newblock {\em arXiv preprint arXiv:2207.13799}.

\bibitem[Knyazev, 2017]{knyazev2017signed}
Knyazev, A.~V. (2017).
\newblock Signed Laplacian for spectral clustering revisited.
\newblock {\em arXiv preprint arXiv:1701.01394}, 1.

\bibitem[Kunegis, 2013]{konect}
Kunegis, J. (2013).
\newblock Konect: the koblenz network collection.
\newblock In {\em Proceedings of the 22nd international conference on world
  wide web}, pages 1343--1350.

\bibitem[Lai et~al., 2018]{Lai2018}
Lai, M., Patti, V., Ruffo, G., and Rosso, P. (2018).
\newblock Stance evolution and Twitter interactions in an Italian political
  debate.
\newblock In Silberztein, M., Atigui, F., Kornyshova, E., M{\'e}tais, E., and
  Meziane, F., editors, {\em Natural Language Processing and Information
  Systems}, pages 15--27, Cham. Springer International Publishing.

\bibitem[Lee et~al., 2020]{gnnasine}
Lee, Y.-C., Seo, N., Han, K., and Kim, S.-W. (2020).
\newblock Asine: Adversarial signed network embedding.
\newblock In {\em Proceedings of the 43rd International ACM SIGIR Conference on
  Research and Development in Information Retrieval}, SIGIR '20, pages
  609--618, New York, NY, USA. Association for Computing Machinery.

\bibitem[Marsden, 2013]{Marsden2013EIGENVALUESOT}
Marsden, A. (2013).
\newblock Eigenvalues of the Laplacian and their relationship to the
  connectedness.
\newblock {NSF REU 2013 paper, University of Chicago}

\bibitem[Mercado et~al., 2019]{means}
Mercado, P., Tudisco, F., and Hein, M. (2019).
\newblock Spectral clustering of signed graphs via matrix power means.
\newblock {\em CoRR}, abs/1905.06230.

\bibitem[Pedregosa et~al., 2011]{scikit-learn}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,
  Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E.
  (2011).
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830.

\bibitem[Rusnak and {\bf Jelena Te\v{s}i\'{c}}, 2021]{2021Cloud}
Rusnak, L. and {\bf Jelena Te\v{s}i\'{c}} (2021).
\newblock Characterizing attitudinal network graphs through frustration cloud.
\newblock {\em Data Mining and Knowledge Discovery}, 6.

\bibitem[Saade et~al., 2014]{Saade2014SpectralCO}
Saade, A., Krzakala, F., and Zdeborov{\'a}, L. (2014).
\newblock Spectral clustering of graphs with the bethe Hessian.
\newblock {\em ArXiv}, abs/1406.1880.

\bibitem[Sampson, 1968]{1968Sampson}
Sampson, S. (1968).
\newblock A novitiate in a period of change: An experimental and case study of
  relationships.
\newblock Ph.D. thesis, Cornell University.

\bibitem[Seo et~al., 2021]{siren}
Seo, C., Jeong, K., Lim, S., and Shin, W. (2021).
\newblock Siren: Sign-aware recommendation using graph neural networks.
\newblock {\em CoRR}, abs/2108.08735.

\bibitem[Traag and ubelj, 2023]{edssjsED801E9B20231201}
Traag, V.~A. and ubelj, L. (2023).
\newblock Large network community detection by fast label propagation.
\newblock {\em Scientific Reports}, 13(1).

\bibitem[Zheng and Skillicorn, 2015]{snsdns}
Zheng, Q. and Skillicorn, D. (2015).
\newblock Spectral embedding of signed networks.
\newblock In {\em Proceedings of the 2015 SIAM International Conference on Data
  Mining (SDM)}, pages 55--63. SIAM.

\end{thebibliography}


\end{document}