\section{Experiments and Ablations}\label{sec:experiments}

In this section we present our results, experiments and ablations. We trained four different models of varying sizes as described in Table \ref{tab:experiment_models}.
\begin{table}[t]
    \centering
    \caption{Hyperparameters for our \modelname{} models of varying model size (for num\_samples = 128).}
    \label{tab:experiment_models}
    \begin{tabular}{ l || r r r r }
    \bf{Model} & $\mathbf{d_{model}}$ & $\mathbf{d_{state}}$ & \bf{\# layer} & \bf{\# Param} \\
    \hline
    \hline
    \modelname{}-S & 256 & 16 & 8 & 4.7\,M \\
    \modelname{}-M & 512 & 16 & 8 & 15.2\,M \\
    \modelname{}-L & 768 & 24 & 12 & 48.7\,M \\
    \modelname{}-XL & 1024 & 24 & 12 & 85.6\,M \\
    \end{tabular}
\end{table}

Throughout the experiments and ablations, we use \modelname{}-L trained on NASA-L (see Table \ref{tab:experiment_datasets}) as our base model if not explicitly stated otherwise.

%###########################################################
% Dataset
%###########################################################
\subsection{Dataset}\label{subsec:experiment_dataset}
We use the discharge cycles for a Li-ion Battery dataset from the NASA Ames Prognostics Center of Excellence (PCoE) \citep{saha2007nasa}.

As depicted in Table \ref{tab:experiment_nasa_battery_specs}, this dataset features multiple Li-ion batteries tested under various discharge profiles, ambient temperatures $T_{amb}$, cut-off voltages $V_{CO}$ and initial capacities.

\begin{table}[t]
    \centering
    \caption{Discharge specifications for various NASA Li-ion batteries. For the profile we report the discharge current signal form and the discharge amplitude. $T_{amb}$ is the ambient temperature, $V_{CO}$ is the cut-off voltage and Initial Capacity is the initial capacity of the battery at the beginning of the measurement campaign.}
    \label{tab:experiment_nasa_battery_specs}
    \begin{tabular}{ l || r r r r }
    \bf{ID} & \bf{Profile} & $\mathbf{T_{amb}}$ & $\mathbf{V_{CO}}$ & \bf{Initial Capacity} \\
    \hline
    \hline
    \#5 & (const.) 2.0A      & 24\,°C & 2.7\,V & 1.8565\,Ah \\
    \#6 & (const.) 2.0A      & 24\,°C & 2.5\,V & 2.0353\,Ah \\
    \#7 & (const.) 2.0A      & 24\,°C & 2.2\,V & 1.8911\,Ah \\
    \#18 & (const.) 2.0A     & 24\,°C & 2.5\,V & 1.8550\,Ah \\
    \#25 & (PWM 0.05Hz) 4.0A & 24\,°C & 2.0\,V & 1.8470\,Ah \\
    \#26 & (PWM 0.05Hz) 4.0A & 24\,°C & 2.2\,V & 1.8133\,Ah \\
    \#27 & (PWM 0.05Hz) 4.0A & 24\,°C & 2.5\,V & 1.8233\,Ah \\
    \#28 & (PWM 0.05Hz) 4.0A & 24\,°C & 2.7\,V & 1.8047\,Ah \\
    \#29 & (const.) 4.0A     & 43\,°C & 2.0\,V & 1.8447\,Ah \\
    \#31 & (const.) 1.5A     & 43\,°C & 2.5\,V & 1.8329\,Ah \\
    \#34 & (const.) 4.0A     & 24\,°C & 2.2\,V & 1.6623\,Ah \\
    \#36 & (const.) 2.0A     & 24\,°C & 2.7\,V & 1.8011\,Ah \\
    \#45 & (const.) 1.0A     &  4\,°C & 2.0\,V & 0.9280\,Ah \\
    \#46 & (const.) 1.0A     &  4\,°C & 2.2\,V & 1.5161\,Ah \\
    \#47 & (const.) 1.0A     &  4\,°C & 2.5\,V & 1.5244\,Ah \\
    \#48 & (const.) 1.0A     &  4\,°C & 2.7\,V & 1.5077\,Ah \\
    \#54 & (const.) 2.0A     &  4\,°C & 2.2\,V & 1.1665\,Ah \\
    \#55 & (const.) 2.0A     &  4\,°C & 2.5\,V & 1.3199\,Ah \\
    \#56 & (const.) 2.0A     &  4\,°C & 2.7\,V & 1.3444\,Ah \\

    \end{tabular}
\end{table}

All those batteries are 18650 NCA cells with a nominal capacity of 2000\,mAh and an upper voltage threshold of 4.2\,V.

In Table \ref{tab:experiment_datasets} we list various training and evaluation splits we compiled from those batteries. NASA-S is the same configuration \cite{mazzi_lithium-ion_2024} was using.

\begin{table}[t]
    \centering
    \caption{Different Training and Evaluation splits for the NASA Li-ion batteries used throughout our experiments and ablations.}
    \label{tab:experiment_datasets}
    \begin{tabular}{ l || r r r}
    \bf{ID} & \bf{NASA-S} & \bf{NASA-M} & \bf{NASA-L}\\
    \hline
    \hline
    \#5 & train & train & train\\
    \#6 & eval & eval & eval \\
    \#7 & eval & eval & eval \\
    \#18 & - & train & train \\
    \#25 & train & - & - \\
    \#26 & - & - & - \\
    \#27 & - & - & - \\
    \#28 & - & - & - \\
    \#29 & train & - & - \\
    \#31 & - & - & train \\
    \#34 & - & - & train \\
    \#36 & - & - & train \\
    \#45 & - & train & train \\
    \#46 & - & train & train \\
    \#47 & eval & eval & eval \\
    \#48 & train & train & train \\
    \#54 & - & - & train \\
    \#55 & - & - & train \\
    \#56 & - & - & train \\

    \end{tabular}
\end{table}

In our pre-processing, we remove cycles that have obvious issues with the measurement setup like those where the measured capacity drops occasionally to 0.0\,mAh. Explicitly we filter those cycles where from one cycle to the next the SOH drops more than 10\,\%. Further, for each cycle we remove those individual samples, that were recorded after the load has been disconnected. We also calculate the time between two cycles that we need for our positional encoding and we resample the time signals to have the same constant number of samples. During training we resample using our anchor-based resampling technique introduced in section \ref{subsec:proposed_method_architecture}. During inference we use linear resampling.

Throughout the experiments and ablations, we use NASA-L as our default dataset if not explicitly stated otherwise.

In Figure \ref{fig:capacity_over_cycle} we show the capacity degradation for all selected and pre-processed batteries. We illustrate the state of health (SOH) in percent over the discharge cycle ID.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{illustrations/capacity_over_cycle.png}
    \caption{Capacity degradation for all selected batteries.}
    \label{fig:capacity_over_cycle}
\end{figure}

%###########################################################
%  Metrics
%###########################################################
\subsection{Metrics}\label{subsec:experiment_metrics}
We evaluate our experiments using the following commonly used metrics for state of health prediction tasks:

\begin{itemize}
    \item \textbf{MAE} mean absolute error:
    \begin{equation}
        \label{eq:mae}
        \text{MAE} = \frac{1}{K}\sum_{k=1}^{K}\left|\text{soh}^{\texttt{gt}}_k-\text{soh}^{\texttt{pred}}_k\right|.
    \end{equation}

    \item \textbf{RMSE} Root mean square error:
    \begin{equation}
        \label{eq:rmse}
        \text{RMSE} = \sqrt{\frac{1}{K}\sum_{k=1}^{K}\left(\text{soh}^{\texttt{gt}}_k-\text{soh}^{\texttt{pred}}_k\right)^2}.
    \end{equation}

    \item \textbf{MAPE} Mean Absolute Percentage Error:
    \begin{equation}
        \label{eq:mape}
        \text{MAPE} = \frac{1}{K}\sum_{k=1}^{K}\frac{\left|\text{soh}^{\texttt{gt}}_k-\text{soh}^{\texttt{pred}}_k\right|}{\left|\text{soh}^{\texttt{gt}}_k\right|},
    \end{equation}

    \item \textbf{AEOLE} Absolute End of Life Error:
    \begin{equation}
        \label{eq:aeole}
        \text{AEOLE} = \left| \text{eol}^{\texttt{gt}} - \text{eol}^{\texttt{pred}} \right|,
    \end{equation}
\end{itemize}


where $\text{soh}^{\texttt{gt}}_k$ is the ground truth for cycle $k$, $\text{soh}^{{\texttt{pred}}}_k$ is the predicted value for cycle $k$, $K$ is the total number of cycles, $\text{eol}^{\texttt{gt}}$ is the ground truth of the end of life indicator and $\text{eol}^{\texttt{pred}}$ is the prediction for the end of life indicator.

%###########################################################
% Experiments
%###########################################################
\subsection{Experiments}\label{subsec:experiment_experiments}

In this section we perform experiments with our \modelname{}-L model trained on NASA-L. In section \ref{subsubsec:experiment_entire_life_time} we show the SOH estimation for the entire battery lifetime. In section \ref{subsubsec:experiment_dataset_split} we show the performance of our model when trained on differently sized datasets. In section \ref{subsubsec:experiment_model_scaling} we show the performance of our model when scaling the model size as well the dataset size. In section \ref{subsubsec:experiment_soh_estimation_different_starting_points} we show the performance of our model when starting the prediction at different cycle IDs simulating pre-aged batteries.

%###########################################################
% SOH Estimation for Entire Battery Lifetime
%###########################################################
\subsubsection{SOH Estimation for Entire Battery Lifetime}\label{subsubsec:experiment_entire_life_time}

As described in section \ref{sec:proposed_method}, we input the resampled time signal from a single discharge cycle and predict the state of health of the battery for that particular cycle. If we sample the model as described in section \ref{subsec:proposed_method_sampling} we can obtain the capacity degradation over the cycle ID for each battery in the evaluation set. Figures \ref{fig:soh_prediction_bat6}, \ref{fig:soh_prediction_bat7}, \ref{fig:soh_prediction_bat47} depict the comparison of the predicted SOH values against the ground truth SOH values. We further show the error for each cycle as well as the resulting EOL indicator. 

The EOL indicator predicts at which cycle the battery reaches its end of life. It is defined as the first cycle bellow the EOL threshold. Due to recuperation effects of Li-ion batteries it is important to consider the last occurrence where the SOH value drops bellow the EOL threshold.

\begin{figure}[t]
    \includegraphics[width=\linewidth]{illustrations/soh_prediction_bat6.png}
    \caption{SOH prediction for Battery \#06}
    \label{fig:soh_prediction_bat6}
\end{figure}

\begin{figure}[t]
    \includegraphics[width=\linewidth]{illustrations/soh_prediction_bat7.png}
    \caption{SOH prediction for Battery \#07}
    \label{fig:soh_prediction_bat7}
\end{figure}

\begin{figure}[t]
    \includegraphics[width=\linewidth]{illustrations/soh_prediction_bat47.png}
    \caption{SOH prediction for Battery \#47}
    \label{fig:soh_prediction_bat47}
\end{figure}

We observe that for the evaluation batteries \#06, \#07 and \#47 our \modelname{} model accurately predicts the dynamics of the SOH curves and predicts the EOL indicator without error. We notice that for battery \#06 the prediction for SOH values above 92\,\% has a comparably large error. We hypothesize that the model does not generalize well given the fact that the dataset is relatively small and that the training set does not contain samples with SOH values above 92\,\% (see Fig. \ref{fig:mazzi_L_distribution}).

\begin{figure}[t]
    \includegraphics[width=\linewidth]{illustrations/nasa_L_distribution.png}
    \caption{Histogram of SOH value counts. Comparison of train and eval split of the NASA-L dataset. Number of bins: 50.}
    \label{fig:mazzi_L_distribution}
\end{figure}

Further, other Mamba-like models such as \cite{li_videomamba_2024} and \cite{ liu_vmamba_2024} have had similar issues with models overfitting easily.

In Table \ref{tab:experiments_results} we compare our \modelname{} model against \cite{mazzi_lithium-ion_2024} for each battery of the evaluation set.

\begin{table}[t]
    \centering
    \caption{Comparing our \modelname{} models with the state-of-the-art \cite{mazzi_lithium-ion_2024} on the NASA Li-ion batteries. We report the MAE, RMSE and MAPE for each battery. The best results are highlighted in bold.}
    \label{tab:experiments_results}
    \begin{tabular}{ l || l | r r r }
    \bf{Battery} & \bf{Model} & \bf{MAE}$\downarrow$ & \bf{RMSE}$\downarrow$ & \bf{MAPE}$\downarrow$ \\
    \hline
    \hline
    \#06 & \citeauthor{mazzi_lithium-ion_2024} & 2.448      & 3.177      & 1.579 \\
         & \modelname{} (ours)                 & \bf{1.173} & \bf{2.068} & \bf{1.406} \\
    \hline
    \#07 & \citeauthor{mazzi_lithium-ion_2024} & 1.861      & 2.252      & 1.114 \\
         & \modelname{} (ours)                 & \bf{1.197} & \bf{1.285} & \bf{1.498} \\
    \hline
    \#47 & \citeauthor{mazzi_lithium-ion_2024} & 2.549      & 3.094      & 1.969 \\
         & \modelname{} (ours)                 & \bf{0.512} & \bf{0.645} & \bf{0.822}
    \end{tabular}
\end{table}


We observe that our \modelname{} model surpasses \cite{mazzi_lithium-ion_2024} in all metrics for all batteries. Later in section \ref{tab:experiments_model_scaling} we show how our method compares against \cite{mazzi_lithium-ion_2024} for different model sizes and and datasets.

%###########################################################
% Dataset Split
%###########################################################
\subsubsection{Dataset Split}\label{subsubsec:experiment_dataset_split}

In this experiment we test the performance of our \modelname{} model when trained on different training sets and compere those results against \cite{mazzi_lithium-ion_2024}. Explicitly, we train our \modelname{}-L model on NASA-S, NASA-M and NASA-L. Results are reported in Table \ref{tab:experiments_data_split}.

\begin{table}[t]
    \centering
    \caption{Performance of our \modelname{} model when trained on different training sets. Evaluation sets are the same for all datasets.}
    \label{tab:experiments_data_split}
    \begin{tabular}{ l l || r r r r }
    \bf{Model} & \bf{Dataset} & \bf{MAE}$\downarrow$ & \bf{RMSE}$\downarrow$ & \bf{MAPE}$\downarrow$ \\
    \hline
    \hline
    \citeauthor{mazzi_lithium-ion_2024} & NASA-S & 2.220 & 2.778 & 1.451 \\
    \hline
    \modelname{} (ours)  & NASA-S & 1.764 & 2.404 & 2.320  \\
                        & NASA-M & 1.334 & 1.902 & 1.641 \\
                        & NASA-L & \bf{1.072} & \bf{1.592} & \bf{1.346}
    \end{tabular}
\end{table}

We observe that our \modelname{} model performs better on MAE and RMSE for all datasets and performs better at MAPE for NASA-L.

%###########################################################
% Model Scaling
%###########################################################
\subsubsection{Model Scaling}\label{subsubsec:experiment_model_scaling}

In this experiment we test the performance of our \modelname{} model when trained with differently sized models. We train our \modelname{}-S, \modelname{}-M, \modelname{}-L and \modelname{}-XL models on NASA-S, NASA-M and NASA-L. The results are reported in Table \ref{tab:experiments_model_scaling}.

\begin{table}[t]
    \centering
    \caption{Model scaling experiment. We report the metrics MAE, RMSE and MAPE for the SOH estimation task for different model sizes and datasets.}
    \label{tab:experiments_model_scaling}
    \begin{tabular}{ l l || r r r r }
    \bf{Model} & \bf{Dataset} & \bf{MAE}$\downarrow$ & \bf{RMSE}$\downarrow$ & \bf{MAPE}$\downarrow$ \\
    \hline
    \hline
    \modelname{}-S & NASA-S & 2.478 & 3.974 & 3.325 \\
                   & NASA-M & 1.920 & 2.829 & 2.461 \\
                   & NASA-L & 1.895 & 2.929 & 2.315 \\
    \hline
    \modelname{}-M & NASA-S  & 1.987 & 2.879 & 2.609\\
                    & NASA-M & 1.736 & 2.414 & 2.170 \\
                    & NASA-L & 1.230 & 2.027 & 1.493 \\
    \hline
    \modelname{}-L & NASA-S & 1.764 & 2.404 & 2.320  \\
                   & NASA-M & 1.334 & 1.902 & 1.641 \\
                   & NASA-L & \bf{1.072} & \bf{1.592} & \bf{1.346} \\
    \hline
    \modelname{}-XL & NASA-S & 1.693 & 2.431 & 2.218 \\
                    & NASA-M & 1.349 & 1.966 & 1.642 \\
                    & NASA-L & 1.133 & 1.800 & 1.396 \\
    \end{tabular}
\end{table}

We can see that the performance of our model increases with the model size and the size of the dataset. This is expected since larger models have more capacity to learn complex patterns in the data and larger datasets provide more data for the model to learn from.

Figure \ref{fig:model_scaling} plots the MAE for the SOH estimation task for the different model sizes and datasets. We can observe that that for \modelname{}-S increasing the dataset size from NASA-M to NASA-L has almost no impact on the performance, indicating that the model is too small to learn from the additional data. 
Further, increasing the model size from \modelname{}-L to \modelname{}-XL decreases the performance slightly indicating that the model is too large for the dataset and likely overfits to the training data. 

\begin{figure}[t]
    \includegraphics[width=\linewidth]{illustrations/model_scaling.png}
    \caption{Model scaling experiment. MAE metric for the SOH estimation task for different model sizes and datasets. Values are reported in Table \ref{tab:experiments_model_scaling}}
    \label{fig:model_scaling}
\end{figure}

%###########################################################
% SOH Estimation for Used Batteries
%###########################################################
\subsubsection{SOH Estimation for Used Batteries}\label{subsubsec:experiment_soh_estimation_different_starting_points}

In a real scenario, one will likely not always need to predict the SOH for new batteries, but also for batteries that have been used for an unknown number of cycles or probably not all discharge cycles have been recorded. A robust model is expected to still reliably predict the SOH values for such scenarios.

To simulate the prediction task of used batteries, we take the batteries from the evaluation set, remove the first discharge cycles and update their cycle ID. Explicitly, for batteries \#06 and \#07 we experiment starting the prediction at cycle 0, 30, 70 and 100 and for battery \#47 with 0, 15, 35 and 50. In Table \ref{tab:experiments_different_starting_points} we report our results.

% NOTE: in mazzi,
% Set A = Bat06 start cycle: 30
% Set B = Bat07 start cycle: 30
% Set C = Bat06 start cycle: 70
% Set D = Bat07 start cycle: 70
% Set E = Bat06 start cycle: 100
% Set F = Bat07 start cycle: 100
% Set G = Bat47 start cycle: 15
% Set H = Bat47 start cycle: 35
% Set I = Bat47 start cycle: 50
\begin{table}[t]
    \centering
    \caption{SOH estimation performance on the evaluation batteries starting at different cycle IDs. We report the metrics MAE, RMSE and MAPE for the SOH estimation task and the AEOLE for EOL indication. Capital letters in brackets for the start column represent \citeauthor{mazzi_lithium-ion_2024} notation for those scenarios. N/R=Not Reported.}
    \label{tab:experiments_different_starting_points}
    \begin{tabular}{ l r || r r r r }
    \bf{Model} & \bf{Start} & \bf{MAE}$\downarrow$ & \bf{RMSE}$\downarrow$ & \bf{MAPE}$\downarrow$ & \bf{AEOLE}$\downarrow$ \\
    \hline
    \hline
    \bf{Battery \#06} & & & & & \\
    \hline
    \citeauthor{mazzi_lithium-ion_2024} &       0 & 2.448 & 3.177 & 1.579 & N/R \\
                                        &  30 (A) & 2.445 & 3.090 & 1.726 & \bf{0} \\
                                        &  70 (C) & 2.080 & 2.516 & 1.650 & 3 \\
                                        & 100 (E) & 2.440 & 2.859 & 1.901 & \bf{0} \\
    \hline
    \modelname{}                        &       0 & \bf{1.173} & \bf{2.068} & \bf{1.406} & \bf{0} \\
                                        &  30 (A) & \bf{0.575} & \bf{0.824} & \bf{0.845} & \bf{0} \\
                                        &  70 (C) & \bf{0.680} & \bf{0.905} & \bf{1.045} & \bf{0} \\
                                        & 100 (E) & \bf{0.808} & \bf{1.045} & \bf{1.275} & \bf{0} \\
    \hline
    \bf{Battery \#07} & & & & & \\
    \hline
    \citeauthor{mazzi_lithium-ion_2024} &       0 & 1.861 & 2.252 & \bf{1.114} & N/R \\
                                        &  30 (B) & 1.748 & 2.285 & \bf{1.092} & N/R \\
                                        &  70 (D) & 1.794 & 2.101 & \bf{1.180} & N/R \\
                                        & 100 (F) & 1.608 & 1.868 & \bf{1.011} & N/R \\
    \hline
    \modelname{}                        &       0 & \bf{1.197} & \bf{1.285} & 1.498 & \bf{0} \\
                                        &  30 (B) & \bf{1.309} & \bf{1.371} & 1.665 & \bf{0} \\
                                        &  70 (D) & \bf{1.400} & \bf{1.433} & 1.839 & \bf{0} \\
                                        & 100 (F) & \bf{1.395} & \bf{1.434} & 1.878 & \bf{0} \\
    \hline
    \bf{Battery \#47} & & & & & \\
    \hline
    \citeauthor{mazzi_lithium-ion_2024} &       0 & 2.549 & 3.094 & 1.969 & N/R \\
                                        &  15 (G) & 2.774 & 3.491 & 2.345 & N/R \\
                                        &  35 (H) & 2.110 & 2.540 & 1.841 & N/R \\
                                        &  50 (I) & 1.806 & 2.416 & 1.570 & N/R \\
    \hline
    \modelname{}                        &       0 & \bf{0.512} & \bf{0.645} & \bf{0.822} & \bf{0} \\
                                        &  15 (G) & \bf{0.507} & \bf{0.638} & \bf{0.843} & \bf{0} \\
                                        &  35 (H) & \bf{0.508} & \bf{0.638} & \bf{0.871} & \bf{0} \\
                                        &  50 (I) & \bf{0.480} & \bf{0.592} & \bf{0.825} & \bf{0}
    
    \end{tabular}
\end{table}

We observe that \modelname{} performs better on all reported metrics for all batteries and starting points, except the MAPE for battery \#07. Since our \modelname{} model performs the prediction task independently for each cycle individually, our method is robust against missing cycles and batteries of different age. The SOH prediction curve is exactly the same. The metrics only vary for different starting points since the metrics are normalized by the total number of cycles $K$ for each battery.

%###########################################################
% Ablation Study
%###########################################################
\subsection{Ablation Study}\label{subsec:ablation_study}
In this section we ablate our contributions and design choices. If not stated otherwise, we use our \modelname{}-L model trained on NASA-L. In section \ref{subsubsec:ablation_tokentype} we ablate the usage and position of the class tokens that can optionally be inserted into the input token sequence. In section \ref{subsubsec:ablation_backbone} we ablate the performance of our \modelname{} backbone and compare it with a vanilla Mamba backbone from \citep{gu_mamba_2024}. We continue investigating the performance for various resampling techniques in section \ref{subsubsec:ablation_resampling}. Finally, we test the performance for different input projections and position encodings in section \ref{subsubsec:ablation_positional_encoding}.

%###########################################################
% Class Token Type
%###########################################################
\subsubsection{Usage and Position of Class Token}\label{subsubsec:ablation_tokentype}
We ablate the usage and the potential position of class tokens inserted into the token sequence. We train our \modelname{}-L model on NASA-L inserting a class token either at the tail, middle or head and compare it with a model that inserts no class token. If we use a class token, the head is attached to the position at the output that corresponds to the position where the class token was placed. If no class token is used, we average the output of all output tokens and feed it to the regression head. The results are reported in Table \ref{tab:ablation_cls_token_type}. 

\begin{table}[t]
    \centering
    \caption{Ablation of inserting a class token into the input token sequence and at which positions.}
    \label{tab:ablation_cls_token_type}
    \begin{tabular}{ l || r r r r}
    \bf{CLS Token Type} & \bf{MAE}$\downarrow$ & \bf{RMSE}$\downarrow$ & \bf{MAPE}$\downarrow$ \\
    \hline
    \hline
    Tail & 5.515 & 8.141 & 6.612  \\
    Middle & 1.977 & 4.131 & 2.260  \\
    Head & 1.746 & 3.384 & 2.029 \\
    None (Avg.) & \bf{1.072} & \bf{1.592} & \bf{1.346} \\
    \end{tabular}
\end{table}

%###########################################################
% Backbone
%###########################################################
\subsubsection{Backbone}\label{subsubsec:ablation_backbone}
In this ablation we compare the performance of our \modelname{} backbone with the vanilla Mamba backbone from \cite{gu_mamba_2024}. We train both models on NASA-L. The results are shown in Table \ref{tab:ablation_backbone}. The main motivation of this ablation is to show the effectiveness of our \modelname{} backbone when it comes to multi-variate time signals.

\begin{table}[t]
    \centering
    \caption{Ablation of different backbone architectures.}
    \label{tab:ablation_backbone}
    \begin{tabular}{ l || r r r}
    \bf{Backbone} & \bf{MAE}$\downarrow$ & \bf{RMSE}$\downarrow$ & \bf{MAPE}$\downarrow$ \\
    \hline
    \hline
    Vanilla Mamba & 1.709 & 2.386 & 2.161 \\
    \modelname{} (ours) & \bf{1.072} & \bf{1.592} & \bf{1.346} \\
    \end{tabular}
\end{table}

We can see that our \modelname{} backbone outperforms the vanilla Mamba backbone. This is due to the fact that the \modelname{} backbone is designed to handle multi-variate time signals and is able to capture the complex relationships between the different variables in the dataset.

%###########################################################
% Resampling
%###########################################################
\subsubsection{Resampling}\label{subsubsec:ablation_resampling}
In this ablation we compare the performance of different resampling methods. We train our \modelname{}-L model on NASA-L using linear, random and our proposed anchor-based resampling. The results are shown in Table~\ref{tab:ablation_resampling}. The target of this ablation is to show the effectiveness of our anchor-based resampling method introduced in section \ref{subsubsec:proposed_method_anchor_based_resampling}.

\begin{table}[t]
    \centering
    \caption{Ablation of various resampling methods.}
    \label{tab:ablation_resampling}
    \begin{tabular}{ l || r r r}
    \bf{Resample Type} & \bf{MAE}$\downarrow$ & \bf{RMSE}$\downarrow$ & \bf{MAPE}$\downarrow$ \\
    \hline
    \hline
    Linear & 1.272 & 1.862 & 1.631 \\
    Random & 3.315 & 4.368 & 4.302 \\
    Anchors (ours) & \bf{1.072} & \bf{1.592} & \bf{1.346} \\
    \end{tabular}
\end{table}

Our anchor-based resampling method outperforms the linear and random resampling methods. We hypothesize that this is due to the fact that the anchor-based resampling acts as a form of data augmentation, allowing the model to learn more robust features from the data. 

%###########################################################
% Positional Encoding
%###########################################################
\subsubsection{Positional Encoding}\label{subsubsec:ablation_positional_encoding}
In this ablation we compare the performance of different positional encoding methods to justify our choice of the sample time positional encoding introduced in section \ref{subsubsec:proposed_method_sample_time_position_embeddings}. We train our \modelname{}-L model on NASA-L using no encoding, sample time encoding and our proposed combined sample time and cycle time difference encoding. The results are shown in Table~\ref{tab:ablation_positional_encoding}. 

\begin{table}[t]
    \centering
    \caption{Ablation for various positional encoding methods.}
    \label{tab:ablation_positional_encoding}
    \begin{tabular}{ l || r r r}
        \bf{Encoding Type} & \bf{MAE}$\downarrow$ & \bf{RMSE}$\downarrow$ & \bf{MAPE}$\downarrow$ \\
        \hline
        \hline
        No Encoding & 3.097 & 3.966 & 4.257 \\
        Sample Time & 1.160 & 1.721 & 1.450 \\
        Sample Time + Cycle Diff (ours) & \bf{1.072} & \bf{1.592} & \bf{1.346} \\
    \end{tabular}
\end{table}

Clearly, adding our proposed positional encoding to the model improves the performance. Further adding the time difference between discharge cycles as an additional feature to the positional encoding increases the performance even further. The intuition is that the difference between discharge cycles is important to capture recuperation effects of the battery and adjust the prediction accordingly.
