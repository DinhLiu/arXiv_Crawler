% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{wang2023real}
W.~Wang, B.~Joshi, N.~Burgdorfer, K.~Batsosc, A.~Q. Lid, P.~Mordohaia, and I.~Rekleitisb, ``Real-time dense 3d mapping of underwater environments,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 5184--5191.

\bibitem{yuval2024releasing}
M.~Yuval and T.~Treibitz, ``Releasing a dataset of 3d models of artificial reefs from the northern red-sea for 3d printing and virtual reality applications,'' \emph{Remote Sensing Applications: Society and Environment}, vol.~36, p. 101305, 2024.

\bibitem{johnson2017high}
M.~Johnson-Roberson, M.~Bryson, A.~Friedman, O.~Pizarro, G.~Troni, P.~Ozog, and J.~C. Henderson, ``High-resolution underwater robotic vision-based mapping and three-dimensional reconstruction for archaeology,'' \emph{Journal of Field Robotics}, vol.~34, no.~4, pp. 625--643, 2017.

\bibitem{llorach2023experience}
G.~Llorach-T{\'o}, E.~Mart{\'\i}nez, J.~D.~R. Fern{\'a}ndez, and E.~Garc{\'\i}a-Ladona, ``Experience obsea: a web-based 3d virtual environment of a seafloor observatory,'' in \emph{OCEANS 2023-Limerick}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1--6.

\bibitem{boittiaux2024sucre}
C.~Boittiaux, R.~Marxer, C.~Dune, A.~Arnaubec, M.~Ferrera, and V.~Hugel, ``Sucre: Leveraging scene structure for underwater color restoration,'' in \emph{2024 International Conference on 3D Vision (3DV)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2024, pp. 1488--1497.

\bibitem{mildenhall2021nerf}
B.~Mildenhall, P.~P. Srinivasan, M.~Tancik, J.~T. Barron, R.~Ramamoorthi, and R.~Ng, ``Nerf: Representing scenes as neural radiance fields for view synthesis,'' \emph{Communications of the ACM}, vol.~65, no.~1, pp. 99--106, 2021.

\bibitem{kerbl20233d}
B.~Kerbl, G.~Kopanas, T.~Leimk{\"u}hler, and G.~Drettakis, ``3d gaussian splatting for real-time radiance field rendering.'' \emph{ACM Trans. Graph.}, vol.~42, no.~4, pp. 139--1, 2023.

\bibitem{zhang2023beyond}
T.~Zhang and M.~Johnson-Roberson, ``Beyond nerf underwater: Learning neural reflectance fields for true color correction of marine imagery,'' \emph{IEEE Robotics and Automation Letters}, 2023.

\bibitem{levy2023seathru}
D.~Levy, A.~Peleg, N.~Pearl, D.~Rosenbaum, D.~Akkaynak, S.~Korman, and T.~Treibitz, ``Seathru-nerf: Neural radiance fields in scattering media,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 56--65.

\bibitem{tang2024neural}
Y.~Tang, C.~Zhu, R.~Wan, C.~Xu, and B.~Shi, ``Neural underwater scene representation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 11\,780--11\,789.

\bibitem{fei20243d}
B.~Fei, J.~Xu, R.~Zhang, Q.~Zhou, W.~Yang, and Y.~He, ``3d gaussian splatting as new era: A survey,'' \emph{IEEE Transactions on Visualization and Computer Graphics}, 2024.

\bibitem{bekerman2020unveiling}
Y.~Bekerman, S.~Avidan, and T.~Treibitz, ``Unveiling optical properties in underwater images,'' in \emph{2020 IEEE International Conference on Computational Photography (ICCP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 1--12.

\bibitem{akkaynak2018revised}
D.~Akkaynak and T.~Treibitz, ``A revised underwater image formation model,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2018, pp. 6723--6732.

\bibitem{nakath2021situ}
D.~Nakath, M.~She, Y.~Song, and K.~K{\"o}ser, ``In-situ joint light and medium estimation for underwater color restoration,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 3731--3740.

\bibitem{yang2024depth}
L.~Yang, B.~Kang, Z.~Huang, X.~Xu, J.~Feng, and H.~Zhao, ``Depth anything: Unleashing the power of large-scale unlabeled data,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 10\,371--10\,381.

\bibitem{barron2022mip}
J.~T. Barron, B.~Mildenhall, D.~Verbin, P.~P. Srinivasan, and P.~Hedman, ``Mip-nerf 360: Unbounded anti-aliased neural radiance fields,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2022, pp. 5470--5479.

\bibitem{muller2022instant}
T.~M{\"u}ller, A.~Evans, C.~Schied, and A.~Keller, ``Instant neural graphics primitives with a multiresolution hash encoding,'' \emph{ACM transactions on graphics (TOG)}, vol.~41, no.~4, pp. 1--15, 2022.

\bibitem{yang2023cross}
Y.~Yang, S.~Zhang, Z.~Huang, Y.~Zhang, and M.~Tan, ``Cross-ray neural radiance fields for novel-view synthesis from unconstrained image collections,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 15\,901--15\,911.

\bibitem{xu2023grid}
L.~Xu, Y.~Xiangli, S.~Peng, X.~Pan, N.~Zhao, C.~Theobalt, B.~Dai, and D.~Lin, ``Grid-guided neural radiance fields for large urban scenes,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 8296--8306.

\bibitem{ramazzina2023scatternerf}
A.~Ramazzina, M.~Bijelic, S.~Walz, A.~Sanvito, D.~Scheuble, and F.~Heide, ``Scatternerf: Seeing through fog with physically-based inverse neural rendering,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 17\,957--17\,968.

\bibitem{dahmani2024swag}
H.~Dahmani, M.~Bennehar, N.~Piasco, L.~Roldao, and D.~Tsishkou, ``Swag: Splatting in the wild images with appearance-conditioned gaussians,'' \emph{arXiv preprint arXiv:2403.10427}, 2024.

\bibitem{zhu2025fsgs}
Z.~Zhu, Z.~Fan, Y.~Jiang, and Z.~Wang, ``Fsgs: Real-time few-shot view synthesis using gaussian splatting,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2025, pp. 145--163.

\bibitem{xiong2023sparsegs}
H.~Xiong, S.~Muttukuru, R.~Upadhyay, P.~Chari, and A.~Kadambi, ``Sparsegs: Real-time 360 $\{$$\backslash$deg$\}$ sparse view synthesis using gaussian splatting,'' \emph{arXiv preprint arXiv:2312.00206}, 2023.

\bibitem{li2024dngaussian}
J.~Li, J.~Zhang, X.~Bai, J.~Zheng, X.~Ning, J.~Zhou, and L.~Gu, ``Dngaussian: Optimizing sparse-view 3d gaussian radiance fields with global-local depth normalization,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 20\,775--20\,785.

\bibitem{paliwal2024coherentgs}
A.~Paliwal, W.~Ye, J.~Xiong, D.~Kotovenko, R.~Ranjan, V.~Chandra, and N.~K. Kalantari, ``Coherentgs: Sparse novel view synthesis with coherent 3d gaussians,'' \emph{arXiv preprint arXiv:2403.19495}, 2024.

\bibitem{chen2024deblur}
W.~Chen and L.~Liu, ``Deblur-gs: 3d gaussian splatting from camera motion blurred images,'' \emph{Proceedings of the ACM on Computer Graphics and Interactive Techniques}, vol.~7, no.~1, pp. 1--15, 2024.

\bibitem{lee2024deblurring}
B.~Lee, H.~Lee, X.~Sun, U.~Ali, and E.~Park, ``Deblurring 3d gaussian splatting,'' \emph{arXiv preprint arXiv:2401.00834}, 2024.

\bibitem{lin2024vastgaussian}
J.~Lin, Z.~Li, X.~Tang, J.~Liu, S.~Liu, J.~Liu, Y.~Lu, X.~Wu, S.~Xu, Y.~Yan \emph{et~al.}, ``Vastgaussian: Vast 3d gaussians for large scene reconstruction,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 5166--5175.

\bibitem{wu20244d}
G.~Wu, T.~Yi, J.~Fang, L.~Xie, X.~Zhang, W.~Wei, W.~Liu, Q.~Tian, and X.~Wang, ``4d gaussian splatting for real-time dynamic scene rendering,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 20\,310--20\,320.

\bibitem{gong2024eggs}
Y.~Gong, ``Eggs: Edge guided gaussian splatting for radiance fields,'' in \emph{Proceedings of the 29th International ACM Conference on 3D Web Technology}, 2024, pp. 1--5.

\bibitem{zhang2024fregs}
J.~Zhang, F.~Zhan, M.~Xu, S.~Lu, and E.~Xing, ``Fregs: 3d gaussian splatting with progressive frequency regularization,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 21\,424--21\,433.

\bibitem{hyung2024effective}
J.~Hyung, S.~Hong, S.~Hwang, J.~Lee, J.~Choo, and J.-H. Kim, ``Effective rank analysis and regularization for enhanced 3d gaussian splatting,'' \emph{arXiv preprint arXiv:2406.11672}, 2024.

\bibitem{zhang2024pixel}
Z.~Zhang, W.~Hu, Y.~Lao, T.~He, and H.~Zhao, ``Pixel-gs: Density control with pixel-aware gradient for 3d gaussian splatting,'' \emph{arXiv preprint arXiv:2403.15530}, 2024.

\bibitem{ye2024absgs}
Z.~Ye, W.~Li, S.~Liu, P.~Qiao, and Y.~Dou, ``Absgs: Recovering fine details in 3d gaussian splatting,'' in \emph{ACM Multimedia 2024}, 2024.

\bibitem{fang2024mini}
G.~Fang and B.~Wang, ``Mini-splatting: Representing scenes with a constrained number of gaussians,'' \emph{arXiv preprint arXiv:2403.14166}, 2024.

\bibitem{turkulainen2024dn}
M.~Turkulainen, X.~Ren, I.~Melekhov, O.~Seiskari, E.~Rahtu, and J.~Kannala, ``Dn-splatter: Depth and normal priors for gaussian splatting and meshing,'' \emph{arXiv preprint arXiv:2403.17822}, 2024.

\bibitem{li2024watersplatting}
H.~Li, W.~Song, T.~Xu, A.~Elsig, and J.~Kulhanek, ``Watersplatting: Fast underwater 3d scene reconstruction using gaussian splatting,'' \emph{arXiv preprint arXiv:2408.08206}, 2024.

\bibitem{zhang2024recgs}
T.~Zhang, W.~Zhi, K.~Huang, J.~Mangelson, C.~Barbalata, and M.~Johnson-Roberson, ``Recgs: Removing water caustic with recurrent gaussian splatting,'' \emph{arXiv preprint arXiv:2407.10318}, 2024.

\bibitem{ancuti2012enhancing}
C.~Ancuti, C.~O. Ancuti, T.~Haber, and P.~Bekaert, ``Enhancing underwater images and videos by fusion,'' in \emph{2012 IEEE conference on computer vision and pattern recognition}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2012, pp. 81--88.

\bibitem{zhang2022underwater}
W.~Zhang, P.~Zhuang, H.-H. Sun, G.~Li, S.~Kwong, and C.~Li, ``Underwater image enhancement via minimal color loss and locally adaptive contrast enhancement,'' \emph{IEEE Transactions on Image Processing}, vol.~31, pp. 3997--4010, 2022.

\bibitem{zhou2024pixel}
J.~Zhou, S.~Wang, Z.~Lin, Q.~Jiang, and F.~Sohel, ``A pixel distribution remapping and multi-prior retinex variational model for underwater image enhancement,'' \emph{IEEE Transactions on Multimedia}, 2024.

\bibitem{badran2023daut}
M.~Badran and M.~Torki, ``Daut: Underwater image enhancement using depth aware u-shape transformer,'' in \emph{2023 IEEE International Conference on Image Processing (ICIP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1830--1834.

\bibitem{li2019underwater}
C.~Li, C.~Guo, W.~Ren, R.~Cong, J.~Hou, S.~Kwong, and D.~Tao, ``An underwater image enhancement benchmark dataset and beyond,'' \emph{IEEE transactions on image processing}, vol.~29, pp. 4376--4389, 2019.

\bibitem{xie2024uveb}
Y.~Xie, L.~Kong, K.~Chen, Z.~Zheng, X.~Yu, Z.~Yu, and B.~Zheng, ``Uveb: A large-scale benchmark and baseline towards real-world underwater video enhancement,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 22\,358--22\,367.

\bibitem{wang2023domain}
Z.~Wang, L.~Shen, M.~Xu, M.~Yu, K.~Wang, and Y.~Lin, ``Domain adaptation for underwater image enhancement,'' \emph{IEEE Transactions on Image Processing}, vol.~32, pp. 1442--1457, 2023.

\bibitem{liu2022twin}
R.~Liu, Z.~Jiang, S.~Yang, and X.~Fan, ``Twin adversarial contrastive learning for underwater image enhancement and beyond,'' \emph{IEEE Transactions on Image Processing}, vol.~31, pp. 4922--4936, 2022.

\bibitem{drews2016underwater}
P.~L. Drews, E.~R. Nascimento, S.~S. Botelho, and M.~F.~M. Campos, ``Underwater depth estimation and image restoration based on single images,'' \emph{IEEE computer graphics and applications}, vol.~36, no.~2, pp. 24--35, 2016.

\bibitem{peng2017underwater}
Y.-T. Peng and P.~C. Cosman, ``Underwater image restoration based on image blurriness and light absorption,'' \emph{IEEE transactions on image processing}, vol.~26, no.~4, pp. 1579--1594, 2017.

\bibitem{akkaynak2019sea}
D.~Akkaynak and T.~Treibitz, ``Sea-thru: A method for removing water from underwater images,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2019, pp. 1682--1691.

\bibitem{berman2020underwater}
D.~Berman, D.~Levy, S.~Avidan, and T.~Treibitz, ``Underwater single image color restoration using haze-lines and a new quantitative dataset,'' \emph{IEEE transactions on pattern analysis and machine intelligence}, vol.~43, no.~8, pp. 2822--2837, 2020.

\bibitem{fu2022unsupervised}
Z.~Fu, H.~Lin, Y.~Yang, S.~Chai, L.~Sun, Y.~Huang, and X.~Ding, ``Unsupervised underwater image restoration: From a homology perspective,'' in \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, vol.~36, no.~1, 2022, pp. 643--651.

\bibitem{sethuraman2023waternerf}
A.~V. Sethuraman, M.~S. Ramanagopal, and K.~A. Skinner, ``Waternerf: Neural radiance fields for underwater scenes,'' in \emph{OCEANS 2023-MTS/IEEE US Gulf Coast}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1--7.

\bibitem{habel2008efficient}
R.~Habel, B.~Mustata, and M.~Wimmer, ``Efficient spherical harmonics lighting with the preetham skylight model.'' in \emph{Eurographics (short papers)}, 2008, pp. 119--122.

\bibitem{fridovich2022plenoxels}
S.~Fridovich-Keil, A.~Yu, M.~Tancik, Q.~Chen, B.~Recht, and A.~Kanazawa, ``Plenoxels: Radiance fields without neural networks,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2022, pp. 5501--5510.

\bibitem{zwicker2001ewa}
M.~Zwicker, H.~Pfister, J.~Van~Baar, and M.~Gross, ``Ewa volume splatting,'' in \emph{Proceedings Visualization, 2001. VIS'01.}\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2001, pp. 29--538.

\bibitem{reiser2024binary}
C.~Reiser, S.~Garbin, P.~Srinivasan, D.~Verbin, R.~Szeliski, B.~Mildenhall, J.~Barron, P.~Hedman, and A.~Geiger, ``Binary opacity grids: Capturing fine geometric detail for mesh-based view synthesis,'' \emph{ACM Transactions on Graphics (TOG)}, vol.~43, no.~4, pp. 1--14, 2024.

\bibitem{rebain2022lolnerf}
D.~Rebain, M.~Matthews, K.~M. Yi, D.~Lagun, and A.~Tagliasacchi, ``Lolnerf: Learn from one look,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 1558--1567.

\bibitem{jiang2021focal}
L.~Jiang, B.~Dai, W.~Wu, and C.~C. Loy, ``Focal frequency loss for image reconstruction and synthesis,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2021, pp. 13\,919--13\,929.

\bibitem{korkmaz2024training}
C.~Korkmaz, A.~M. Tekalp, and Z.~Dogan, ``Training generative image super-resolution models by wavelet-domain losses enables better control of artifacts,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 5926--5936.

\bibitem{liu2024mm}
Y.~Liu, C.~Yu, J.~Cheng, Z.~J. Wang, and X.~Chen, ``Mm-net: A mixformer-based multi-scale network for anatomical and functional image fusion,'' \emph{IEEE Transactions on Image Processing}, vol.~33, pp. 2197--2212, 2024.

\bibitem{schonberger2016structure}
J.~L. Schonberger and J.-M. Frahm, ``Structure-from-motion revisited,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2016, pp. 4104--4113.

\bibitem{murez2015photometric}
Z.~Murez, T.~Treibitz, R.~Ramamoorthi, and D.~Kriegman, ``Photometric stereo in a scattering medium,'' in \emph{Proceedings of the IEEE international conference on computer vision}, 2015, pp. 3415--3423.

\bibitem{peng2023u}
L.~Peng, C.~Zhu, and L.~Bian, ``U-shape transformer for underwater image enhancement,'' \emph{IEEE Transactions on Image Processing}, vol.~32, pp. 3066--3079, 2023.

\bibitem{gaurav2005ciede2000}
G.~Sharma, W.~Wu, and E.~N. Dalal, ``The ciede2000 color-difference formula: Implementation notes, supplementary test data, and mathematical observations,'' \emph{COLOR research \& application}, vol.~30, no.~1, pp. 21--30, 2005.

\end{thebibliography}
